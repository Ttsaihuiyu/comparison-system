import os
import sys
import subprocess
import torch
import numpy as np
import networkx as nx
import pandas as pd
import time
from pathlib import Path

# Add RL_recommender to Python path
RL_RECOMMENDER_PATH = Path("../RL_recommender").resolve()
sys.path.append(str(RL_RECOMMENDER_PATH))

def build_nx_graph_with_output(output_container=None):
    """
    å»ºç«‹ç”¨æˆ¶-é›»å½±ç¶²çµ¡åœ–ï¼Œæ”¯æŒ Streamlit è¼¸å‡º
    """
    ratings_file = "data/train.dat"

    try:
        ratings = pd.read_csv(ratings_file,
                            sep=',',
                            engine='python',
                            names=['UserID', 'MovieID', 'Rating', 'Timestamp'],
                            encoding='ISO-8859-1')
    except FileNotFoundError:
        error_msg = f"éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æª”æ¡ˆ {ratings_file}"
        if output_container:
            output_container.error(error_msg)
        raise FileNotFoundError(error_msg)

    if output_container:
        output_container.text(f"æˆåŠŸè¼‰å…¥ {len(ratings)} ç­†è©•åˆ†è³‡æ–™")

    # å»ºç«‹ä½¿ç”¨è€…-é›»å½± é›™é‚Šåœ– (Bipartite Graph)
    if output_container:
        output_container.text("å»ºç«‹ä½¿ç”¨è€…-é›»å½± é›™é‚Šåœ–...")
    
    start_time = time.time()
    B = nx.Graph()

    # æ·»åŠ ç¯€é»ï¼Œä¸¦æ¨™è¨˜ç¯€é»é¡å‹ (bipartite=0 for users, bipartite=1 for movies)
    users = sorted(ratings['UserID'].unique())
    movies = sorted(ratings['MovieID'].unique())
    
    for uid in users:
        B.add_node(f"u{uid}", bipartite=0)

    for mid in movies:
        B.add_node(f"m{mid}", bipartite=1)

    edges = [(f"u{row['UserID']}", f"m{row['MovieID']}")
            for _, row in ratings.iterrows()]
    B.add_edges_from(edges)
    
    end_time = time.time()
    
    if output_container:
        output_container.text(f"åœ–å»ºç«‹å®Œæˆã€‚è€—æ™‚: {end_time - start_time:.2f} ç§’")
        output_container.text(f"ç¯€é»æ•¸é‡: {B.number_of_nodes()} (Users: {len(users)}, Movies: {len(movies)})")
        output_container.text(f"é‚Šæ•¸é‡: {B.number_of_edges()}")

    # æª¢æŸ¥åœ–æ˜¯å¦é€£é€š
    if nx.is_connected(B):
        if output_container:
            output_container.text("åœ–æ˜¯é€£é€šçš„")
    else:
        if output_container:
            output_container.text("åœ–ä¸æ˜¯é€£é€šçš„ï¼Œå°‡å€‹åˆ¥åµæ¸¬ç¤¾ç¾¤")
    
    return B

def heuristic_exposure_strategy_wrapper(user_item_graph, rec_item_set, item_emb, output_container=None,
                                       n_selected_communities=2,
                                       n_diverse_users_per_community=10,
                                       n_items_per_user=3):
    """
    ä¿®æ”¹éçš„ heuristic exposure ç­–ç•¥å‡½æ•¸ï¼Œå¸¶æœ‰ Streamlit è¼¸å‡ºæ”¯æŒ
    """
    from sklearn.metrics.pairwise import cosine_similarity
    import community.community_louvain as community_louvain
    from collections import defaultdict, Counter
    
    def calculate_ILS(item_emb, rec_item_set):
        if len(rec_item_set) <= 1:
            return 0.0
        embeddings = item_emb[rec_item_set].cpu().detach().numpy()
        sim_matrix = cosine_similarity(embeddings)
        np.fill_diagonal(sim_matrix, 0)
        k = len(rec_item_set)
        ils = np.sum(sim_matrix) / (k * (k - 1))
        return ils

    # ä½¿ç”¨Louvainç®—æ³•æª¢æ¸¬ç¤¾ç¾¤
    if output_container:
        output_container.text("æ­£åœ¨æª¢æ¸¬ç¤¾ç¾¤...")

    connected_components = list(nx.connected_components(user_item_graph))
    if output_container:
        output_container.text(f"ç¸½å…±æœ‰ {len(connected_components)} å€‹é€£é€šå…ƒä»¶")

    all_partition = community_louvain.best_partition(user_item_graph, resolution=2, random_state=42)
    communities = all_partition
    
    if output_container:
        output_container.text(f"ç¸½ç¤¾ç¾¤æ•¸é‡: {len(set(communities.values()))}")

    # å°‡ç¯€é»åˆ†ç‚ºç”¨æˆ¶ç¯€é»å’Œé …ç›®ç¯€é»
    users = [node for node in user_item_graph.nodes() if user_item_graph.nodes[node].get('bipartite') == 0]
    items = [node for node in user_item_graph.nodes() if user_item_graph.nodes[node].get('bipartite') == 1]
    
    if output_container:
        output_container.text(f"ç”¨æˆ¶ç¯€é»æ•¸: {len(users)}, é›»å½±ç¯€é»æ•¸: {len(items)}")
    
    # ç‚ºæ¯å€‹ç¤¾ç¾¤åˆ†é…ç”¨æˆ¶å’Œé …ç›®
    community_users = defaultdict(list)
    community_items = defaultdict(list)
    
    for node, community_id in communities.items():
        if node in users:
            community_users[community_id].append(node)
        elif node in items:
            community_items[community_id].append(node)
    
    # éæ¿¾æ‰å°‘æ–¼3å€‹useræˆ–3å€‹itemçš„ç¤¾ç¾¤
    valid_communities = [comm_id for comm_id in set(communities.values())
                        if len(community_users[comm_id]) > 2 and len(community_items[comm_id]) > 2]
    
    if output_container:
        output_container.text("Top ç¤¾ç¾¤è³‡è¨Šï¼ˆå‰5ï¼‰:")
        comm_sizes = Counter(communities.values())
        for i, (comm_id, size) in enumerate(comm_sizes.most_common(5)):
            n_users = len(community_users[comm_id])
            n_items = len(community_items[comm_id])
            output_container.text(f"ç¤¾ç¾¤ {comm_id}: ç¸½ç¯€é»={size}, ä½¿ç”¨è€…={n_users}, é›»å½±={n_items}")
    
    if len(valid_communities) < 2:
        if output_container:
            output_container.warning("è­¦å‘Š: æœ‰æ•ˆç¤¾ç¾¤æ•¸é‡ä¸è¶³ï¼Œç„¡æ³•é€²è¡Œè·¨ç¤¾ç¾¤æ›å…‰")
        return []
    
    if output_container:
        output_container.text(f"æœ‰æ•ˆç¤¾ç¾¤æ•¸é‡: {len(valid_communities)}")
    
    # éš¨æ©Ÿé¸æ“‡ç¤¾ç¾¤
    if len(valid_communities) < n_selected_communities:
        if output_container:
            output_container.warning(f"è­¦å‘Š: æœ‰æ•ˆç¤¾ç¾¤æ•¸é‡({len(valid_communities)})å°æ–¼è«‹æ±‚æ•¸é‡({n_selected_communities})")
        selected_indices = valid_communities
    else:
        selected_indices = np.random.choice(valid_communities, 
                                            size=n_selected_communities, 
                                            replace=False)

    all_selected_items = []
    # å¾è¢«é¸åˆ°çš„ç¤¾ç¾¤å‰µå»ºæ›å…‰é‚Š
    for i in range(len(selected_indices)):
        source_idx = selected_indices[i]

        # è¨ˆç®—ç¤¾ç¾¤ä¸­æ¯å€‹ç”¨æˆ¶çš„äº¤äº’é …ç›®é›†åˆçš„å¤šæ¨£æ€§å¾—åˆ†(ILS)
        user_diversity_scores = {}
        for user in community_users[source_idx]:
            user = ''.join(filter(str.isdigit, user))
            if int(user) < len(rec_item_set):
                user_items = rec_item_set[int(user)]
                if len(user_items) > 1:
                    user_diversity_scores[user] = calculate_ILS(item_emb, user_items)
        
        if not user_diversity_scores:
            continue
        
        # é¸æ“‡ILSæœ€ä½çš„ç”¨æˆ¶(æœ€å¤šæ¨£åŒ–çš„ç”¨æˆ¶)
        diverse_users = sorted(user_diversity_scores.keys(), 
                                key=lambda u: user_diversity_scores[u])
        diverse_users = diverse_users[:min(n_diverse_users_per_community, len(diverse_users))]

        # ç‚ºæ¯å€‹å¤šæ¨£åŒ–ç”¨æˆ¶é¸æ“‡æ­·å²äº¤äº’é …ç›®
        for user in diverse_users:
            user_items = list(user_item_graph.neighbors(f"u{user}"))
            
            if len(user_items) == 0:
                continue
            
            # éš¨æ©Ÿé¸æ“‡ä¸€äº›é …ç›®
            selected_items = np.random.choice(user_items, 
                                            size=min(n_items_per_user, len(user_items)), 
                                            replace=False)
            for item_node_id in selected_items:
                item_node_id = ''.join(filter(str.isdigit, item_node_id))
                all_selected_items.append((int(user), int(item_node_id)))  

    if output_container:
        output_container.text(f"å·²ç”Ÿæˆ {len(all_selected_items)} æ¢æ›å…‰é‚Š")
    
    return all_selected_items

def get_user_recommendations(user_embeddings, item_embeddings, user_id, num_recommendations=5):
    """
    ç‚ºç‰¹å®šç”¨æˆ¶ç”Ÿæˆé›»å½±æ¨è–¦
    """
    with torch.no_grad():
        # è¨ˆç®—ç”¨æˆ¶å’Œæ‰€æœ‰é›»å½±çš„ç›¸ä¼¼åº¦
        user_emb = user_embeddings[user_id].unsqueeze(0)  # shape: (1, emb_dim)
        scores = torch.mm(user_emb, item_embeddings.t()).squeeze()  # shape: (num_items,)
        
        # ç²å– top-k æ¨è–¦
        _, top_items = torch.topk(scores, num_recommendations)
        
        return top_items.cpu().numpy(), scores[top_items].cpu().numpy()

def run_heuristic_exposure(output_container=None, target_user_id=None, num_recommendations=5):
    """
    é‹è¡Œ Heuristic Exposure æ¨¡å‹çš„åŒ…è£å‡½æ•¸
    """
    if output_container:
        output_container.text("æ­£åœ¨å•Ÿå‹• Heuristic Exposure æ¨¡å‹...")
    
    try:
        # åˆ‡æ›åˆ° RL_recommender ç›®éŒ„
        original_dir = os.getcwd()
        os.chdir(RL_RECOMMENDER_PATH)
        
        # æ·»åŠ ç•¶å‰ç›®éŒ„åˆ° Python è·¯å¾‘
        if str(RL_RECOMMENDER_PATH) not in sys.path:
            sys.path.insert(0, str(RL_RECOMMENDER_PATH))
        
        if output_container:
            output_container.text("æ­£åœ¨è¼‰å…¥å¿…è¦æ¨¡çµ„...")
        
        # ç›´æ¥ä½¿ç”¨æˆ‘å€‘è‡ªå·±çš„å‡½æ•¸
        try:
            
            if output_container:
                output_container.text("æ­£åœ¨è¼‰å…¥æ¨¡å‹æ–‡ä»¶...")
            
            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
            user_embeddings = torch.load("model/simulator/user_emb.pt", map_location=device, weights_only=True)
            item_embeddings = torch.load("model/simulator/item_emb.pt", map_location=device, weights_only=True)
            
            if output_container:
                output_container.text(f"æˆåŠŸè¼‰å…¥æ¨¡å‹: {user_embeddings.shape[0]} å€‹ç”¨æˆ¶, {item_embeddings.shape[0]} å€‹é›»å½±")
            
            # æª¢æŸ¥ç”¨æˆ¶IDæ˜¯å¦æœ‰æ•ˆ
            if target_user_id is not None:
                if target_user_id >= user_embeddings.shape[0] or target_user_id < 0:
                    error_msg = f"ç”¨æˆ¶ID {target_user_id} è¶…å‡ºç¯„åœ (0-{user_embeddings.shape[0]-1})"
                    if output_container:
                        output_container.error(error_msg)
                    os.chdir(original_dir)
                    return error_msg
                
                # ç‚ºç‰¹å®šç”¨æˆ¶ç”Ÿæˆæ¨è–¦
                if output_container:
                    output_container.text(f"æ­£åœ¨ç‚ºç”¨æˆ¶ {target_user_id} ç”Ÿæˆæ¨è–¦...")
                
                recommended_items, scores = get_user_recommendations(
                    user_embeddings, item_embeddings, target_user_id, num_recommendations
                )
                
                # åˆ‡æ›å›åŸç›®éŒ„
                os.chdir(original_dir)
                
                if output_container:
                    output_container.success("å€‹äººåŒ–æ¨è–¦å®Œæˆï¼")
                    output_container.subheader(f"ğŸ¬ ç‚ºç”¨æˆ¶ {target_user_id} æ¨è–¦çš„é›»å½±")
                    
                    # å‰µå»ºæ¨è–¦çµæœè¡¨æ ¼
                    import pandas as pd
                    recommendations_df = pd.DataFrame({
                        'æ’å': range(1, len(recommended_items) + 1),
                        'é›»å½±ID': recommended_items,
                        'æ¨è–¦åˆ†æ•¸': [f"{score:.4f}" for score in scores]
                    })
                    
                    output_container.dataframe(recommendations_df, use_container_width=True)
                    
                                    # é¡¯ç¤ºæ¨è–¦è©³æƒ…
                output_container.subheader("ğŸ“Š æ¨è–¦è©³æƒ…")
                
                # ä½¿ç”¨åˆ—è¡¨æ–¹å¼é¡¯ç¤ºæ‰€æœ‰æ¨è–¦
                recommendation_text = ""
                for i, (movie_id, score) in enumerate(zip(recommended_items, scores)):
                    recommendation_text += f"ğŸ­ ç¬¬ {i+1} åï¼šé›»å½± {movie_id} (åˆ†æ•¸: {score:.4f})\n"
                
                output_container.text(recommendation_text)
                
                return f"æˆåŠŸç‚ºç”¨æˆ¶ {target_user_id} æ¨è–¦äº† {len(recommended_items)} éƒ¨é›»å½±"
                
            else:
                # åŸå§‹çš„æ‰¹é‡æ¨è–¦é‚è¼¯
                # å‰µå»ºæ¨è–¦é …ç›®é›†åˆ
                rec_item_set = [np.random.choice(range(item_embeddings.shape[0]), size=20, replace=False).tolist() 
                               for user in range(user_embeddings.shape[0])]
                
                if output_container:
                    output_container.text("æ­£åœ¨å»ºç«‹ç”¨æˆ¶-é›»å½±ç¶²çµ¡...")
                
                user_item_graph = build_nx_graph_with_output(output_container)
                
                if output_container:
                    output_container.text("æ­£åœ¨åŸ·è¡Œ Heuristic Exposure ç­–ç•¥...")
                
                # åŸ·è¡Œæˆ‘å€‘è‡ªå·±çš„æ¨¡å‹å‡½æ•¸
                selected_items = heuristic_exposure_strategy_wrapper(
                    user_item_graph, rec_item_set, item_embeddings, output_container
                )
                
                # åˆ‡æ›å›åŸç›®éŒ„
                os.chdir(original_dir)
                
                if output_container:
                    output_container.success("Heuristic Exposure æ¨¡å‹åŸ·è¡ŒæˆåŠŸï¼")
                    output_container.subheader("æ¨è–¦çµæœæ‘˜è¦")
                    output_container.text(f"ğŸ¬ ç¸½å…±ç”Ÿæˆäº† {len(selected_items)} å€‹æ¨è–¦é…å°")
                    
                    if len(selected_items) > 0:
                        unique_users = len(set([item[0] for item in selected_items]))
                        unique_movies = len(set([item[1] for item in selected_items]))
                        output_container.text(f"ğŸ‘¥ æ¶‰åŠç”¨æˆ¶æ•¸é‡: {unique_users}")
                        output_container.text(f"ğŸ­ æ¶‰åŠé›»å½±æ•¸é‡: {unique_movies}")
                        
                        output_container.subheader("æ¨è–¦ç¯„ä¾‹ï¼ˆå‰10å€‹ï¼‰")
                        for i, (user_id, movie_id) in enumerate(selected_items[:10]):
                            output_container.text(f"ç”¨æˆ¶ {user_id} â†’ é›»å½± {movie_id}")
                    else:
                        output_container.warning("æ²’æœ‰ç”Ÿæˆä»»ä½•æ¨è–¦é…å°")
                            
                return f"æˆåŠŸç”Ÿæˆ {len(selected_items)} å€‹æ¨è–¦é…å°"
            
        except ImportError as e:
            error_msg = f"æ¨¡çµ„å°å…¥å¤±æ•—: {str(e)}"
            if output_container:
                output_container.error(error_msg)
            os.chdir(original_dir)
            return error_msg
        except Exception as e:
            error_msg = f"åŸ·è¡Œéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}"
            if output_container:
                output_container.error(error_msg)
            os.chdir(original_dir)
            return error_msg
            
    except Exception as e:
        error_msg = f"æ¨¡å‹åŸ·è¡Œå‡ºéŒ¯: {str(e)}"
        if output_container:
            output_container.error(error_msg)
        os.chdir(original_dir)
        return error_msg

def run_rl_exposure(output_container=None, target_user_id=None, num_recommendations=5):
    if output_container:
        output_container.text("æ­£åœ¨å•Ÿå‹• RL Exposure æ¨¡å‹...")
        
    # å¦‚æœæŒ‡å®šäº†ç‰¹å®šç”¨æˆ¶ï¼Œä½¿ç”¨ç°¡åŒ–çš„æ¨è–¦é‚è¼¯
    if target_user_id is not None:
        if output_container:
            output_container.info("ä½¿ç”¨åŸºæ–¼ RL åµŒå…¥çš„å€‹äººåŒ–æ¨è–¦...")
        
        try:
            # åˆ‡æ›åˆ° RL_recommender ç›®éŒ„
            original_dir = os.getcwd()
            os.chdir(RL_RECOMMENDER_PATH)
            
            if output_container:
                output_container.text("æ­£åœ¨è¼‰å…¥ RL è¨“ç·´çš„åµŒå…¥...")
            
            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
            user_embeddings = torch.load("model/simulator/user_emb.pt", map_location=device, weights_only=True)
            item_embeddings = torch.load("model/simulator/item_emb.pt", map_location=device, weights_only=True)
            
            if output_container:
                output_container.text(f"æˆåŠŸè¼‰å…¥æ¨¡å‹: {user_embeddings.shape[0]} å€‹ç”¨æˆ¶, {item_embeddings.shape[0]} å€‹é›»å½±")
            
            # æª¢æŸ¥ç”¨æˆ¶IDæ˜¯å¦æœ‰æ•ˆ
            if target_user_id >= user_embeddings.shape[0] or target_user_id < 0:
                error_msg = f"ç”¨æˆ¶ID {target_user_id} è¶…å‡ºç¯„åœ (0-{user_embeddings.shape[0]-1})"
                if output_container:
                    output_container.error(error_msg)
                os.chdir(original_dir)
                return error_msg
            
            # ç‚ºç‰¹å®šç”¨æˆ¶ç”Ÿæˆæ¨è–¦ï¼ˆä½¿ç”¨ RL å„ªåŒ–çš„åµŒå…¥ï¼‰
            if output_container:
                output_container.text(f"æ­£åœ¨ç‚ºç”¨æˆ¶ {target_user_id} ç”Ÿæˆ RL å„ªåŒ–æ¨è–¦...")
            
            recommended_items, scores = get_user_recommendations(
                user_embeddings, item_embeddings, target_user_id, num_recommendations
            )
            
            # åˆ‡æ›å›åŸç›®éŒ„
            os.chdir(original_dir)
            
            if output_container:
                output_container.success("RL å€‹äººåŒ–æ¨è–¦å®Œæˆï¼")
                output_container.subheader(f"ğŸ¤– ç‚ºç”¨æˆ¶ {target_user_id} çš„ RL æ¨è–¦çµæœ")
                
                # å‰µå»ºæ¨è–¦çµæœè¡¨æ ¼
                recommendations_df = pd.DataFrame({
                    'æ’å': range(1, len(recommended_items) + 1),
                    'é›»å½±ID': recommended_items,
                    'RL åˆ†æ•¸': [f"{score:.4f}" for score in scores]
                })
                
                output_container.dataframe(recommendations_df, use_container_width=True)
                
                # é¡¯ç¤ºæ¨è–¦è©³æƒ…
                output_container.subheader("ğŸ§  RL æ¨è–¦è©³æƒ…")
                
                # ä½¿ç”¨åˆ—è¡¨æ–¹å¼é¡¯ç¤ºæ‰€æœ‰æ¨è–¦
                recommendation_text = ""
                for i, (movie_id, score) in enumerate(zip(recommended_items, scores)):
                    recommendation_text += f"ğŸ¤– ç¬¬ {i+1} åï¼šé›»å½± {movie_id} (RLåˆ†æ•¸: {score:.4f})\n"
                
                output_container.text(recommendation_text)
            
            return f"æˆåŠŸç‚ºç”¨æˆ¶ {target_user_id} ç”Ÿæˆäº† {len(recommended_items)} éƒ¨ RL æ¨è–¦é›»å½±"
            
        except Exception as e:
            error_msg = f"RL å€‹äººåŒ–æ¨è–¦åŸ·è¡Œå‡ºéŒ¯: {str(e)}"
            if output_container:
                output_container.error(error_msg)
            os.chdir(original_dir)
            return error_msg
    
    else:
        # åŸå§‹çš„å®Œæ•´ RL è¨“ç·´é‚è¼¯
        if output_container:
            output_container.info("æ³¨æ„ï¼šå®Œæ•´ RL æ¨¡å‹éœ€è¦æ›´é•·çš„åŸ·è¡Œæ™‚é–“ï¼Œè«‹è€å¿ƒç­‰å¾…...")
        
        try:
            # åˆ‡æ›åˆ° RL_recommender ç›®éŒ„
            original_dir = os.getcwd()
            os.chdir(RL_RECOMMENDER_PATH)
            
            if output_container:
                output_container.text("æ­£åœ¨åŸ·è¡Œå®Œæ•´ RL è¨“ç·´...")
            
            # é‹è¡Œ RL exposure è…³æœ¬
            result = subprocess.run(
                [sys.executable, "exposure_method/rl_exposure_main.py"],
                capture_output=True,
                text=True,
                timeout=600  # 10åˆ†é˜è¶…æ™‚ï¼ˆRLè¨“ç·´å¯èƒ½éœ€è¦æ›´é•·æ™‚é–“ï¼‰
            )
            
            # åˆ‡æ›å›åŸç›®éŒ„
            os.chdir(original_dir)
            
            if result.returncode == 0:
                if output_container:
                    output_container.success("RL Exposure æ¨¡å‹åŸ·è¡ŒæˆåŠŸï¼")
                    output_container.text("è¼¸å‡ºçµæœï¼š")
                    output_container.code(result.stdout)
                return result.stdout
            else:
                error_msg = f"æ¨¡å‹åŸ·è¡Œå¤±æ•—: {result.stderr}"
                if output_container:
                    output_container.error(error_msg)
                return error_msg
            
        except subprocess.TimeoutExpired:
            error_msg = "æ¨¡å‹åŸ·è¡Œè¶…æ™‚ï¼ˆè¶…é10åˆ†é˜ï¼‰"
            if output_container:
                output_container.error(error_msg)
            os.chdir(original_dir)
            return error_msg
        except Exception as e:
            error_msg = f"æ¨¡å‹åŸ·è¡Œå‡ºéŒ¯: {str(e)}"
            if output_container:
                output_container.error(error_msg)
            os.chdir(original_dir)
            return error_msg

def check_model_dependencies():
    """
    æª¢æŸ¥æ¨¡å‹ä¾è³´æ˜¯å¦æ»¿è¶³
    
    è¿”å›:
    bool: ä¾è³´æ˜¯å¦æ»¿è¶³
    """
    try:
        # æª¢æŸ¥ RL_recommender ç›®éŒ„æ˜¯å¦å­˜åœ¨
        if not RL_RECOMMENDER_PATH.exists():
            return False, f"RL_recommender ç›®éŒ„ä¸å­˜åœ¨: {RL_RECOMMENDER_PATH}"
        
        # æª¢æŸ¥é—œéµæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        heuristic_file = RL_RECOMMENDER_PATH / "exposure_method" / "heuristic_exposure.py"
        rl_file = RL_RECOMMENDER_PATH / "exposure_method" / "rl_exposure_main.py"
        
        if not heuristic_file.exists():
            return False, f"Heuristic exposure æ–‡ä»¶ä¸å­˜åœ¨: {heuristic_file}"
        
        if not rl_file.exists():
            return False, f"RL exposure æ–‡ä»¶ä¸å­˜åœ¨: {rl_file}"
        
        # æª¢æŸ¥æ¨¡å‹æ–‡ä»¶
        user_emb_file = RL_RECOMMENDER_PATH / "model" / "simulator" / "user_emb.pt"
        item_emb_file = RL_RECOMMENDER_PATH / "model" / "simulator" / "item_emb.pt"
        train_data_file = RL_RECOMMENDER_PATH / "data" / "train.dat"
        
        if not user_emb_file.exists():
            return False, f"ç”¨æˆ¶åµŒå…¥æ–‡ä»¶ä¸å­˜åœ¨: {user_emb_file}"
            
        if not item_emb_file.exists():
            return False, f"é …ç›®åµŒå…¥æ–‡ä»¶ä¸å­˜åœ¨: {item_emb_file}"
            
        if not train_data_file.exists():
            return False, f"è¨“ç·´æ•¸æ“šæ–‡ä»¶ä¸å­˜åœ¨: {train_data_file}"
        
        return True, "æ‰€æœ‰ä¾è³´æª¢æŸ¥é€šé"
        
    except Exception as e:
        return False, f"ä¾è³´æª¢æŸ¥å‡ºéŒ¯: {str(e)}" 