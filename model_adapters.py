# model_adapters.py
import pandas as pd
import torch
import torch.nn as nn
import os
import pickle
import sys
from pathlib import Path
from datetime import datetime
import numpy as np

# ğŸ”§ ç›´æ¥åœ¨é€™è£¡å®šç¾©æ‰€æœ‰éœ€è¦çš„é¡å’Œå‡½æ•¸ï¼Œä¸ä¾è³´å¤–éƒ¨å°å…¥ï¼

# ====== ç›´æ¥è¤‡è£½ LightGCNConv ======
# ä½¿ç”¨æ¢ä»¶å°å…¥é¿å… IDE å ±éŒ¯
import importlib.util

TORCH_GEOMETRIC_AVAILABLE = importlib.util.find_spec("torch_geometric") is not None

if TORCH_GEOMETRIC_AVAILABLE:
    try:
        from torch_geometric.nn import MessagePassing
        
        class LightGCNConv(MessagePassing):
            def __init__(self): 
                super().__init__(aggr='add')
            
            def forward(self, x, edge_index):
                row, col = edge_index
                deg = torch.bincount(row, minlength=x.size(0)).float()
                deg_inv_sqrt = deg.pow(-0.5)
                deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0
                norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]
                return self.propagate(edge_index, x=x, norm=norm)
            
            def message(self, x_j, norm): 
                return norm.view(-1, 1) * x_j
        
        print("âœ… ä½¿ç”¨ torch_geometric ç‰ˆæœ¬çš„ LightGCNConv")
        
    except ImportError:
        TORCH_GEOMETRIC_AVAILABLE = False

if not TORCH_GEOMETRIC_AVAILABLE:
    print("âš ï¸ torch_geometric æœªå®‰è£ï¼Œä½¿ç”¨ç°¡åŒ–ç‰ˆæœ¬")
    
    class LightGCNConv(nn.Module):
        """ç°¡åŒ–ç‰ˆ LightGCNConvï¼Œä¸ä¾è³´ torch_geometric"""
        def __init__(self):
            super().__init__()
        
        def forward(self, x, edge_index):
            row, col = edge_index
            deg = torch.bincount(row, minlength=x.size(0)).float()
            deg_inv_sqrt = deg.pow(-0.5)
            deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0
            edge_weight = deg_inv_sqrt[row] * deg_inv_sqrt[col]
            
            # æ‰‹å‹•å¯¦ç¾æ¶ˆæ¯å‚³æ’­
            out = torch.zeros_like(x)
            for i in range(edge_index.shape[1]):
                src, dst = edge_index[0, i], edge_index[1, i]
                out[dst] += edge_weight[i] * x[src]
            
            return out

# ====== ç›´æ¥è¤‡è£½ LightGCN ======
class LightGCN(nn.Module):
    def __init__(self, num_users, num_items, emb_size=64, n_layers=2):
        super().__init__()
        self.num_users, self.num_items = num_users, num_items
        self.embedding = nn.Embedding(num_users + num_items, emb_size)
        nn.init.xavier_uniform_(self.embedding.weight)
        self.convs = nn.ModuleList([LightGCNConv() for _ in range(n_layers)])
    
    def forward(self, edge_index):
        x = self.embedding.weight
        embs = [x]
        for conv in self.convs:
            x = conv(x, edge_index)
            embs.append(x)
        return torch.stack(embs).mean(0)
    
    def get_user_item(self, edge_index):
        all_emb = self(edge_index)
        return all_emb[:self.num_users], all_emb[self.num_users:]

# ====== ç›´æ¥è¤‡è£½ build_edge_index ======
def build_edge_index(pairs, num_users):
    """æ§‹å»ºé›™å‘é‚Šç´¢å¼•"""
    edges = []
    for u, i in pairs:
        edges.append((u, i + num_users))
        edges.append((i + num_users, u))
    return torch.tensor(edges, dtype=torch.long).t().contiguous()

# ====== åŸæœ‰çš„å…¨åŸŸè®Šæ•¸å’Œå‡½æ•¸ ======
RL_RECOMMENDER_PATH = Path(__file__).parent.parent / "RL_recommender"
sys.path.append(str(RL_RECOMMENDER_PATH))

# Global variable to cache model and edge_index
_cached_model = None
_cached_edge_index = None
_cached_n_user = None
_cached_n_item = None

def initialize_model_for_dynamic_updates():
    global _cached_model, _cached_edge_index, _cached_n_user, _cached_n_item
    
    try:
        # åˆ‡æ›åˆ° RL_recommender ç›®éŒ„
        original_dir = os.getcwd()
        os.chdir(RL_RECOMMENDER_PATH)
        
        # è¼‰å…¥æ˜ å°„ä¿¡æ¯
        with open('mapping/uid_map.pkl', 'rb') as f:
            uid_map = pickle.load(f)
        with open('mapping/mid_map.pkl', 'rb') as f:
            mid_map = pickle.load(f)
        
        n_user = len(uid_map)
        n_item = len(mid_map)
        
        # è¼‰å…¥ embeddings
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        user_emb = torch.load("model/RS/user_emb.pt", map_location=device, weights_only=True)
        item_emb = torch.load("model/RS/item_emb.pt", map_location=device, weights_only=True)
        
        # ğŸ¯ ç¾åœ¨ç”¨æœ¬æ–‡ä»¶ä¸­å®šç¾©çš„ LightGCNï¼
        model = LightGCN(n_user, n_item, emb_size=64, n_layers=2).to(device)
        combined_emb = torch.cat([user_emb, item_emb], dim=0)
        model.embedding.weight.data = combined_emb
        
        # ğŸ¯ ç¾åœ¨ç”¨æœ¬æ–‡ä»¶ä¸­å®šç¾©çš„ build_edge_indexï¼
        train_df = pd.read_csv('data/train.dat', sep=',', names=['user_id', 'movie_id', 'rating', 'timestamp'])
        interactions = [(row['user_id'], row['movie_id']) for _, row in train_df.iterrows()]
        edge_index = build_edge_index(interactions, n_user).to(device)
        
        # å„²å­˜åˆ°å…¨åŸŸè®Šæ•¸
        _cached_model = model
        _cached_edge_index = edge_index
        _cached_n_user = n_user
        _cached_n_item = n_item
        
        os.chdir(original_dir)
        print(f"âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆ - ç”¨æˆ¶: {n_user}, ç‰©å“: {n_item}, é‚Šæ•¸: {edge_index.shape[1]}")
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±æ•—: {str(e)}")
        import traceback
        print(f"âŒ è©³ç´°éŒ¯èª¤: {traceback.format_exc()}")
        if 'original_dir' in locals():
            os.chdir(original_dir)
        return False

def update_embeddings_after_like(user_id, movie_id):
    """
    è¶…ç°¡åŒ–ç‰ˆï¼šé»è®šå¾Œç›´æ¥æ›´æ–°ä¸¦é‡æ–°è¨ˆç®—
    """
    global _cached_model, _cached_edge_index, _cached_n_user
    
    if _cached_model is None:
        print("âš ï¸ æ¨¡å‹æœªåˆå§‹åŒ–")
        return None, None
    
    try:
        # æ·»åŠ æ–°é‚Š
        device = _cached_edge_index.device
        new_edges = torch.tensor([
            [user_id, movie_id + _cached_n_user],
            [movie_id + _cached_n_user, user_id]
        ], device=device).t()
        
        # æ›´æ–° edge_index
        updated_edge_index = torch.cat([_cached_edge_index, new_edges], dim=1)
        updated_edge_index = torch.unique(updated_edge_index, dim=1)
        
        # ğŸ¯ æ‚¨èªªçš„ï¼šç›´æ¥åŸ·è¡Œé€™å€‹ functionï¼
        with torch.no_grad():
            new_user_emb, new_item_emb = _cached_model.get_user_item(updated_edge_index)
        
        # æ›´æ–°å¿«å–
        _cached_edge_index = updated_edge_index
        
        print(f"âœ… ç›´æ¥åŸ·è¡Œ get_user_item() å®Œæˆï¼ç”¨æˆ¶{user_id}å–œæ­¡é›»å½±{movie_id}")
        return new_user_emb, new_item_emb
        
    except Exception as e:
        print(f"âŒ æ›´æ–°å¤±æ•—: {str(e)}")
        import traceback
        print(f"âŒ è©³ç´°éŒ¯èª¤: {traceback.format_exc()}")
        return None, None

def get_dynamic_recommendations(user_id, num_recommendations=20, exclude_ids=None):
    """
    ä½¿ç”¨å‹•æ…‹æ›´æ–°çš„ embeddings ç”Ÿæˆæ¨è–¦
    """
    # å…ˆå˜—è©¦ç²å–æ›´æ–°å¾Œçš„ embeddings
    user_emb, item_emb = update_embeddings_after_like(user_id, 0)  # dummy call to get current embeddings
    
    if user_emb is None:
        return None, None
    
    with torch.no_grad():
        user_vec = user_emb[user_id].unsqueeze(0)
        scores = torch.mm(user_vec, item_emb.t()).squeeze()
        
        if exclude_ids:
            scores[exclude_ids] = -float('inf')
        
        top_scores, top_items = torch.topk(scores, num_recommendations)
        return top_items.cpu().numpy(), top_scores.cpu().numpy()

def load_movie_info():
    try:
        movies_df = pd.read_csv(RL_RECOMMENDER_PATH / "raw" / "ml-1m" / "movies.dat", 
                               sep='::', names=['Movie_ID', 'Title', 'Genres'], 
                               engine='python', encoding='latin-1')
        movies_info = {}
        for _, row in movies_df.iterrows():
            genres = row['Genres'].split('|') if pd.notna(row['Genres']) else ['Unknown']
            movies_info[row['Movie_ID']] = {
                'title': row['Title'],
                'genres': genres
            }
        return movies_info
    except Exception as e:
        print(f"Error loading movie info: {e}")
        return {}

def load_user_info():
    try:
        users_df = pd.read_csv(RL_RECOMMENDER_PATH / "raw" / "ml-1m" / "users.dat", 
                              sep='::', names=['User_ID', 'Gender', 'Age', 'Occupation', 'Zip'], 
                              engine='python')
        users_info = {}
        for _, row in users_df.iterrows():
            users_info[row['User_ID']] = {
                'gender': row['Gender'],
                'age': row['Age'],
                'occupation': row['Occupation'],
                'zip': row['Zip']
            }
        return users_info
    except Exception as e:
        print(f"Error loading user info: {e}")
        return {}

def load_mapping_files():
    try:
        uid_map_file = RL_RECOMMENDER_PATH / "mapping" / "uid_map.pkl"
        mid_map_file = RL_RECOMMENDER_PATH / "mapping" / "mid_map.pkl"
        
        with open(uid_map_file, 'rb') as f:
            uid_map = pickle.load(f)
        with open(mid_map_file, 'rb') as f:
            mid_map = pickle.load(f)
        
        reverse_uid_map = {v: k for k, v in uid_map.items()}
        reverse_mid_map = {v: k for k, v in mid_map.items()}
        
        return uid_map, mid_map, reverse_uid_map, reverse_mid_map, True
    except Exception as e:
        print(f"Error loading mapping files: {e}")
        return None, None, None, None, False

def get_user_recommendations(user_embeddings, item_embeddings, user_id, num_recommendations=20, exclude_ids=None):
    """åŸºæœ¬æ¨è–¦åŠŸèƒ½"""
    with torch.no_grad():
        user_emb = user_embeddings[user_id].unsqueeze(0)
        scores = torch.mm(user_emb, item_embeddings.t()).squeeze()
        
        if exclude_ids and isinstance(exclude_ids, list) and len(exclude_ids) > 0:
            scores[exclude_ids] = -float('inf')
        
        top_scores, top_items = torch.topk(scores, num_recommendations)
        return top_items.cpu().numpy(), top_scores.cpu().numpy()

def find_similar_users(user_embeddings, target_user_id, num_similar_users=2):
    """
    æ‰¾åˆ°èˆ‡ç›®æ¨™ç”¨æˆ¶æœ€ç›¸ä¼¼çš„ç”¨æˆ¶
    """
    with torch.no_grad():
        target_emb = user_embeddings[target_user_id].unsqueeze(0)  # shape: (1, emb_dim)
        
        # è¨ˆç®—èˆ‡æ‰€æœ‰ç”¨æˆ¶çš„ç›¸ä¼¼åº¦ï¼ˆä½¿ç”¨é¤˜å¼¦ç›¸ä¼¼åº¦ï¼‰
        similarities = torch.cosine_similarity(target_emb, user_embeddings, dim=1)
        
        # å°‡ç›®æ¨™ç”¨æˆ¶è‡ªå·±çš„ç›¸ä¼¼åº¦è¨­ç‚ºè² ç„¡çª®å¤§ï¼Œé¿å…æ¨è–¦è‡ªå·±
        similarities[target_user_id] = -float('inf')
        
        # ç²å–æœ€ç›¸ä¼¼çš„ç”¨æˆ¶
        _, top_users = torch.topk(similarities, num_similar_users)
        similarity_scores = similarities[top_users]
        
        return top_users.cpu().numpy(), similarity_scores.cpu().numpy()

def get_user_watched_movies(user_id, reverse_uid_map, reverse_mid_map, num_movies=5):
    """
    ç²å–æŒ‡å®šç”¨æˆ¶çœ‹éçš„é›»å½±ï¼ˆæŒ‰è©•åˆ†æ’åºï¼Œå–é«˜åˆ†é›»å½±ï¼‰
    """
    try:
        # è®€å–æ•¸æ“š
        train_df = pd.read_csv(RL_RECOMMENDER_PATH / 'data/train.dat', sep=',', names=['user_id', 'movie_id', 'rating', 'timestamp'])
        val_df = pd.read_csv(RL_RECOMMENDER_PATH / 'data/val.dat', sep=',', names=['user_id', 'movie_id', 'rating', 'timestamp'])
        test_df = pd.read_csv(RL_RECOMMENDER_PATH / 'data/test.dat', sep=',', names=['user_id', 'movie_id', 'rating', 'timestamp'])
        
        combined = pd.concat([train_df, val_df, test_df])
        
        # æ‰¾åˆ°è©²ç”¨æˆ¶çš„æ‰€æœ‰äº¤äº’è¨˜éŒ„
        user_interactions = combined[combined['user_id'] == user_id].copy()
        
        if user_interactions.empty:
            return []
        
        # æŒ‰è©•åˆ†é™åºæ’åºï¼Œé¸æ“‡é«˜åˆ†é›»å½±
        user_interactions = user_interactions.sort_values(['rating', 'timestamp'], ascending=[False, False])
        
        # å–å‰ num_movies éƒ¨é›»å½±
        top_movies = user_interactions.head(num_movies)
        
        # è½‰æ›ç‚ºåŸå§‹é›»å½±ID
        watched_movies = []
        for _, row in top_movies.iterrows():
            original_movie_id = reverse_mid_map.get(row['movie_id'])
            if original_movie_id is not None:
                watched_movies.append({
                    'movie_id': original_movie_id,
                    'rating': row['rating']
                })
        
        return watched_movies
        
    except Exception as e:
        print(f"ç²å–ç”¨æˆ¶è§€çœ‹é›»å½±å¤±æ•—: {str(e)}")
        return []

def run_heuristic_exposure(output_container=None, target_user_id=None, num_recommendations=20):
    """
    é‹è¡Œ Heuristic Exposure æ¨¡å‹ - ä½¿ç”¨ user embedding å’Œ item embedding
    """
    try:
        # åˆ‡æ›åˆ° RL_recommender ç›®éŒ„
        original_dir = os.getcwd()
        os.chdir(RL_RECOMMENDER_PATH)
        
        # è¼‰å…¥ç”¨æˆ¶å’Œé›»å½±ä¿¡æ¯
        movies_info = load_movie_info()
        users_info = load_user_info()
        
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        user_embeddings = torch.load("model/RS/user_emb.pt", map_location=device, weights_only=True)
        item_embeddings = torch.load("model/RS/item_emb.pt", map_location=device, weights_only=True)
        
        # è½½å…¥æ˜ å°„æ–‡ä»¶
        uid_map, mid_map, reverse_uid_map, reverse_mid_map, mapping_success = load_mapping_files()
        
        if not mapping_success:
            error_msg = "ç„¡æ³•è¼‰å…¥æ˜ å°„æ–‡ä»¶"
            if output_container:
                output_container.error(error_msg)
            os.chdir(original_dir)
            return error_msg
        
        # ç²å–ç”¨æˆ¶æ­·å²äº¤äº’è¨˜éŒ„ï¼Œä»¥ä¾¿éæ¿¾æ¨è–¦
        user_interactions_df, watched_movie_ids = get_user_interactions(target_user_id, reverse_uid_map, reverse_mid_map)
        
        # æª¢æŸ¥ç”¨æˆ¶IDæ˜¯å¦æœ‰æ•ˆ
        if target_user_id >= user_embeddings.shape[0] or target_user_id < 0:
            error_msg = f"ç”¨æˆ¶ID {target_user_id} è¶…å‡ºç¯„åœ (0-{user_embeddings.shape[0]-1})"
            if output_container:
                output_container.error(error_msg)
            os.chdir(original_dir)
            return error_msg
        
        # ç‚ºç‰¹å®šç”¨æˆ¶ç”Ÿæˆæ¨è–¦ï¼Œä¸¦æ’é™¤å·²è§€çœ‹é›»å½±
        recommended_items, scores = get_user_recommendations(
            user_embeddings, item_embeddings, target_user_id, num_recommendations,
            exclude_ids=watched_movie_ids
        )
        
        # åˆ‡æ›å›åŸç›®éŒ„
        os.chdir(original_dir)
        
        if output_container:
            output_container.success("Heuristic æ¨è–¦å®Œæˆï¼")
            
            # é¡¯ç¤ºç”¨æˆ¶ä¿¡æ¯
            user_info = users_info.get(target_user_id + 1, {})  # ç”¨æˆ¶IDå¾1é–‹å§‹
            if user_info:
                output_container.subheader(f"ğŸ‘¤ ç”¨æˆ¶ {target_user_id} çš„è©³ç´°ä¿¡æ¯")
                # ä½¿ç”¨è¡¨æ ¼å½¢å¼ç¢ºä¿å®Œæ•´é¡¯ç¤º
                import pandas as pd
                user_data = pd.DataFrame({
                    'æ€§åˆ¥': [user_info['gender']],
                    'å¹´é½¡': [user_info['age']],
                    'è·æ¥­': [user_info['occupation']],
                    'æ­·å²äº¤äº’': [f"{len(watched_movie_ids)} éƒ¨é›»å½±"]
                })
                output_container.dataframe(user_data, use_container_width=True, hide_index=True)

            output_container.subheader(f"ğŸ¯ ç‚ºç”¨æˆ¶ {target_user_id} çš„ Heuristic æ¨è–¦çµæœ")
            
            # å‰µå»ºè©³ç´°çš„æ¨è–¦çµæœè¡¨æ ¼
            recommendations_data = []
            for i, (item_id, score) in enumerate(zip(recommended_items, scores)):
                # æ­£ç¢ºçš„IDæ˜ å°„é‚è¼¯ï¼šå°‡æ˜ å°„å¾Œçš„item_idè½‰æ›ç‚ºåŸå§‹é›»å½±ID
                original_movie_id = reverse_mid_map.get(item_id)
                if original_movie_id is None:
                    continue  # è·³éç„¡æ³•æ˜ å°„çš„é›»å½±
                
                movie_info = movies_info.get(original_movie_id, {})
                movie_title = movie_info.get('title', 'æœªçŸ¥é›»å½±')
                movie_genres = ' | '.join(movie_info.get('genres', ['æœªçŸ¥']))
                
                recommendations_data.append({
                    'æ’å': i + 1,
                    'é›»å½±ID': original_movie_id,
                    'é›»å½±åç¨±': movie_title,
                    'é¡å‹': movie_genres,
                    'æ¨è–¦åˆ†æ•¸': f"{score:.4f}"
                })
            
            recommendations_df = pd.DataFrame(recommendations_data)
            
            # æ·»åŠ è¡¨æ ¼æ¨™é¡Œ
            col1, col2, col3, col4, col5, col6 = output_container.columns([1, 1, 4, 3, 2, 3])
            with col1:
                output_container.write("**æ’å**")
            with col2:
                output_container.write("**é›»å½±ID**")
            with col3:
                output_container.write("**é›»å½±åç¨±**")
            with col4:
                output_container.write("**é¡å‹**")
            with col5:
                output_container.write("**æ¨è–¦åˆ†æ•¸**")
            with col6:
                output_container.write("**å–œæ„›**")
            
            output_container.write("---")
            
            # é¡¯ç¤ºæ¨è–¦çµæœè¡¨æ ¼ï¼Œä¸¦ç‚ºæ¯è¡Œæ·»åŠ æ„›å¿ƒæŒ‰éˆ•
            for i, (item_id, score) in enumerate(zip(recommended_items, scores)):
                # æ­£ç¢ºçš„IDæ˜ å°„é‚è¼¯ï¼šå°‡æ˜ å°„å¾Œçš„item_idè½‰æ›ç‚ºåŸå§‹é›»å½±ID
                original_movie_id = reverse_mid_map.get(item_id)
                if original_movie_id is None:
                    continue  # è·³éç„¡æ³•æ˜ å°„çš„é›»å½±
                
                movie_info = movies_info.get(original_movie_id, {})
                movie_title = movie_info.get('title', 'æœªçŸ¥é›»å½±')
                movie_genres = ' | '.join(movie_info.get('genres', ['æœªçŸ¥']))
                
                col1, col2, col3, col4, col5, col6 = output_container.columns([1, 1, 4, 3, 2, 1])
                
                with col1:
                    output_container.write(f"**{i+1}**")
                with col2:
                    output_container.write(f"{original_movie_id}")  # é¡¯ç¤ºåŸå§‹é›»å½±ID
                with col3:
                    output_container.write(f"**{movie_title}**")
                with col4:
                    output_container.write(f"{movie_genres}")
                with col5:
                    output_container.write(f"{score:.4f}")
                with col6:
                    if output_container.button("â¤ï¸", key=f"heart_{target_user_id}_{i}", help="åŠ å…¥æˆ‘çš„æœ€æ„›"):
                        # æ·»åŠ åˆ°ç”¨æˆ¶äº¤äº’è¨˜éŒ„ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹é›»å½±ID
                        success = add_movie_to_interactions(target_user_id, original_movie_id, movie_info, reverse_uid_map, reverse_mid_map)
                        
                        if success:
                            output_container.success(f"â¤ï¸ å·²å°‡ã€Š{movie_title}ã€‹æ·»åŠ åˆ°äº¤äº’è¨˜éŒ„ï¼")
                            # æ›´æ–° session_state ä¸­çš„äº¤äº’è¨˜éŒ„
                            import streamlit as st
                            if 'recommendations_data' in st.session_state:
                                # é‡æ–°ç²å–æ›´æ–°å¾Œçš„äº¤äº’è¨˜éŒ„
                                updated_interactions_df, updated_watched_ids = get_user_interactions(target_user_id, reverse_uid_map, reverse_mid_map)
                                st.session_state.recommendations_data['user_interactions_df'] = updated_interactions_df
                                st.session_state.recommendations_data['watched_movie_ids'] = updated_watched_ids
                        else:
                            output_container.error("âŒ æ·»åŠ å¤±æ•—ï¼Œè«‹ç¨å¾Œå†è©¦")
            
            # é¡¯ç¤ºç”¨æˆ¶æ­·å²äº¤äº’è¨˜éŒ„
            if not user_interactions_df.empty:
                output_container.subheader(f"ğŸ“š ç”¨æˆ¶ {target_user_id} çš„æ­·å²äº¤äº’è¨˜éŒ„")
                output_container.info(f"æ•¸æ“šå·²ä¿å­˜è‡³: user_{target_user_id}_interactions.csv")
                
                # æŒ‰æ™‚é–“æˆ³é™åºæ’åˆ—
                sorted_interactions = user_interactions_df.sort_values('Timestamp', ascending=False)
                
                # é¡¯ç¤ºæ‰€æœ‰äº¤äº’è¨˜éŒ„
                output_container.dataframe(sorted_interactions, use_container_width=True)
                
                # é¡¯ç¤ºçµ±è¨ˆä¿¡æ¯
                output_container.info(f"ğŸ“Š å…± {len(sorted_interactions)} æ¢äº¤äº’è¨˜éŒ„")
            else:
                output_container.warning("è©²ç”¨æˆ¶æ²’æœ‰æ­·å²äº¤äº’è¨˜éŒ„")
        
        return f"æˆåŠŸç‚ºç”¨æˆ¶ {target_user_id} ç”Ÿæˆäº† {len(recommended_items)} éƒ¨æ¨è–¦é›»å½±"
        
    except Exception as e:
        error_msg = f"Heuristic æ¨è–¦åŸ·è¡Œå‡ºéŒ¯: {str(e)}"
        if output_container:
            output_container.error(error_msg)
        os.chdir(original_dir)
        return error_msg

def check_model_dependencies():
    """
    æª¢æŸ¥æ¨¡å‹ä¾è³´æ˜¯å¦æ»¿è¶³
    """
    try:
        # æª¢æŸ¥ RL_recommender ç›®éŒ„æ˜¯å¦å­˜åœ¨
        if not RL_RECOMMENDER_PATH.exists():
            return False, f"RL_recommender ç›®éŒ„ä¸å­˜åœ¨: {RL_RECOMMENDER_PATH}"
        
        # æª¢æŸ¥æ¨¡å‹æ–‡ä»¶
        user_emb_file = RL_RECOMMENDER_PATH / "model" / "RS" / "user_emb.pt"
        item_emb_file = RL_RECOMMENDER_PATH / "model" / "RS" / "item_emb.pt"
        
        if not user_emb_file.exists():
            return False, f"ç”¨æˆ¶åµŒå…¥æ–‡ä»¶ä¸å­˜åœ¨: {user_emb_file}"
            
        if not item_emb_file.exists():
            return False, f"é …ç›®åµŒå…¥æ–‡ä»¶ä¸å­˜åœ¨: {item_emb_file}"
        
        return True, "æ‰€æœ‰ä¾è³´æª¢æŸ¥é€šé"
        
    except Exception as e:
        return False, f"ä¾è³´æª¢æŸ¥å‡ºéŒ¯: {str(e)}"

def get_user_interactions(target_user_id, reverse_uid_map, reverse_mid_map):
    try:
        # 1ï¸âƒ£ é¦–å…ˆå˜—è©¦è®€å–ç”¨æˆ¶å°ˆé–€çš„äº¤äº’è¨˜éŒ„æ–‡ä»¶ï¼ˆå‘å¾Œå…¼å®¹ï¼‰
        original_user_id = reverse_uid_map.get(target_user_id, target_user_id)
        interaction_file = RL_RECOMMENDER_PATH / "interaction_collect" / f"user_{original_user_id}_interactions.csv"
        
        if interaction_file.exists():
            user_interactions_df = pd.read_csv(interaction_file)
            watched_movie_ids = []
            for movie_id in user_interactions_df['Movie_ID']:
                mapped_id = None
                for mapped, original in reverse_mid_map.items():
                    if original == movie_id:
                        mapped_id = mapped
                        break
                if mapped_id is not None:
                    watched_movie_ids.append(mapped_id)
            
            return user_interactions_df, watched_movie_ids
        
        # 2ï¸âƒ£ ç›´æ¥å¾ /data ç›®éŒ„è®€å–æ­·å²äº¤äº’è³‡æ–™
        else:
            print(f"ğŸ“ å¾ /data ç›®éŒ„è®€å–ç”¨æˆ¶ {target_user_id} çš„æ­·å²äº¤äº’è¨˜éŒ„")
            
            # è®€å–æ‰€æœ‰æ•¸æ“šæ–‡ä»¶
            data_files = ['train.dat', 'val.dat', 'test.dat']
            all_interactions = []
            
            for data_file in data_files:
                file_path = RL_RECOMMENDER_PATH / "data" / data_file
                if file_path.exists():
                    try:
                        df = pd.read_csv(file_path, sep=',', names=['user_id', 'movie_id', 'rating', 'timestamp'])
                        user_data = df[df['user_id'] == target_user_id]
                        if not user_data.empty:
                            all_interactions.append(user_data)
                            print(f"âœ… å¾ {data_file} ä¸­æ‰¾åˆ° {len(user_data)} æ¢è¨˜éŒ„")
                    except Exception as e:
                        print(f"âš ï¸ è®€å– {data_file} å¤±æ•—: {str(e)}")
            
            if not all_interactions:
                print(f"ğŸ“­ ç”¨æˆ¶ {target_user_id} æ²’æœ‰ä»»ä½•æ­·å²äº¤äº’è¨˜éŒ„")
                return pd.DataFrame(columns=['Movie_ID', 'Title', 'Genres', 'Rating', 'Timestamp']), []
            
            # åˆä½µæ‰€æœ‰äº¤äº’è¨˜éŒ„
            combined_interactions = pd.concat(all_interactions, ignore_index=True)
            
            # è¼‰å…¥é›»å½±ä¿¡æ¯ç”¨æ–¼å‰µå»ºè©³ç´°è¨˜éŒ„
            movies_info = load_movie_info()
            
            # è½‰æ›ç‚ºç”¨æˆ¶äº¤äº’æ ¼å¼
            user_interactions_data = []
            watched_movie_ids = []
            
            for _, row in combined_interactions.iterrows():
                mapped_movie_id = row['movie_id']  # å·²ç¶“æ˜¯æ˜ å°„å¾Œçš„ID
                
                # è½‰æ›å›åŸå§‹é›»å½±IDç”¨æ–¼é¡¯ç¤º
                original_movie_id = reverse_mid_map.get(mapped_movie_id)
                if original_movie_id is not None:
                    movie_info = movies_info.get(original_movie_id, {})
                    
                    user_interactions_data.append({
                        'Movie_ID': original_movie_id,
                        'Title': movie_info.get('title', 'æœªçŸ¥é›»å½±'),
                        'Genres': ' | '.join(movie_info.get('genres', ['æœªçŸ¥'])),
                        'Rating': row['rating'],
                        'Timestamp': row['timestamp']
                    })
                    
                    # æ·»åŠ åˆ°è§€çœ‹éçš„é›»å½±åˆ—è¡¨ï¼ˆä½¿ç”¨æ˜ å°„å¾Œçš„IDï¼‰
                    watched_movie_ids.append(mapped_movie_id)
            
            user_interactions_df = pd.DataFrame(user_interactions_data)
            print(f"ğŸ“Š ç”¨æˆ¶ {target_user_id} ç¸½å…±æœ‰ {len(user_interactions_df)} æ¢æ­·å²äº¤äº’è¨˜éŒ„")
            
            return user_interactions_df, watched_movie_ids
            
    except Exception as e:
        print(f"âŒ ç²å–ç”¨æˆ¶äº¤äº’è¨˜éŒ„å¤±æ•—: {str(e)}")
        import traceback
        print(f"âŒ è©³ç´°éŒ¯èª¤: {traceback.format_exc()}")
        return pd.DataFrame(columns=['Movie_ID', 'Title', 'Genres', 'Rating', 'Timestamp']), []

def add_to_liked_movies(user_id, movie_info, liked_movies_file):
    """
    å°†ç”µå½±æ·»åŠ åˆ°ç”¨æˆ·å–œå¥½åå•
    """
    # åˆ›å»ºæ–°çš„å–œå¥½è®°å½•
    new_like = {
        'user_id': user_id,
        'movie_id': movie_info.get('movie_id'),
        'movie_title': movie_info.get('title'),
        'genres': movie_info.get('genres'),
        'liked_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    }
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    try:
        if os.path.exists(liked_movies_file):
            liked_df = pd.read_csv(liked_movies_file)
        else:
            liked_df = pd.DataFrame()
        
        # æ·»åŠ æ–°è®°å½•
        liked_df = pd.concat([liked_df, pd.DataFrame([new_like])], ignore_index=True)
        
        # ä¿å­˜æ–‡ä»¶
        liked_df.to_csv(liked_movies_file, index=False)
        return True
        
    except Exception as e:
        print(f"ä¿å­˜å–œå¥½è®°å½•å¤±è´¥: {str(e)}")
        return False

def get_user_liked_movies(user_id):
    """
    è·å–ç”¨æˆ·çš„å–œå¥½ç”µå½±åå•
    """
    liked_movies_file = f"user_{user_id}_liked_movies.csv"
    
    try:
        if os.path.exists(liked_movies_file):
            return pd.read_csv(liked_movies_file)
        else:
            return pd.DataFrame()
    except Exception as e:
        print(f"è¯»å–å–œå¥½è®°å½•å¤±è´¥: {str(e)}")
        return pd.DataFrame()

def add_movie_to_interactions(user_id, original_movie_id, movie_info, reverse_uid_map, reverse_mid_map):
    try:
        print(f"ğŸ” é–‹å§‹è™•ç†: ç”¨æˆ¶{user_id}, åŸå§‹é›»å½±ID{original_movie_id}")
        
        original_dir = os.getcwd()
        os.chdir(RL_RECOMMENDER_PATH)
        print(f"ğŸ“ åˆ‡æ›åˆ°ç›®éŒ„: {RL_RECOMMENDER_PATH}")
        
        train_file = "data/train.dat"
        
        mid_map_file = RL_RECOMMENDER_PATH / "mapping" / "mid_map.pkl"
        with open(mid_map_file, 'rb') as f:
            mid_map = pickle.load(f)
        
        mapped_movie_id = mid_map.get(original_movie_id)
        if mapped_movie_id is None:
            print(f"âŒ åŸå§‹é›»å½±ID {original_movie_id} ä¸åœ¨æ˜ å°„ä¸­")
            os.chdir(original_dir)
            return False
        
        print(f"âœ… é›»å½±IDæ˜ å°„æˆåŠŸ: åŸå§‹ID{original_movie_id} -> æ˜ å°„ID{mapped_movie_id}")
        
        current_timestamp = int(datetime.now().timestamp())
        new_interaction = f"{user_id},{mapped_movie_id},5,{current_timestamp}\n"
        print(f"ğŸ“ æ–°äº¤äº’è¨˜éŒ„: {new_interaction.strip()}")
        
        with open(train_file, 'a', encoding='utf-8') as f:
            f.write(new_interaction)
        print(f"âœ… å·²æ·»åŠ åˆ° {train_file}")
        
        # ğŸ¯ è¶…ç°¡åŒ–ç‰ˆï¼šç›´æ¥èª¿ç”¨ get_user_item()
        try:
            new_user_emb, new_item_emb = update_embeddings_after_like(user_id, mapped_movie_id)
            if new_user_emb is not None:
                print(f"ğŸ‰ ç›´æ¥åŸ·è¡Œ get_user_item() æˆåŠŸï¼")
            else:
                print(f"âš ï¸ å‹•æ…‹æ›´æ–°å¤±æ•—ï¼Œä½†æ•¸æ“šå·²ä¿å­˜")
        except Exception as embed_error:
            print(f"âš ï¸ å‹•æ…‹æ›´æ–°é‡åˆ°å•é¡Œ: {str(embed_error)}")
        
        interaction_file = f"interaction_collect/user_{user_id}_interactions.csv"
        
        new_record = pd.DataFrame({
            'Movie_ID': [original_movie_id],
            'Title': [movie_info.get('title', 'æœªçŸ¥é›»å½±')],
            'Genres': [' | '.join(movie_info.get('genres', ['æœªçŸ¥']))],
            'Rating': [5],
            'Timestamp': [current_timestamp]
        })
        
        if os.path.exists(interaction_file):
            existing_df = pd.read_csv(interaction_file)
            if original_movie_id not in existing_df['Movie_ID'].values:
                updated_df = pd.concat([new_record, existing_df], ignore_index=True)
                updated_df.to_csv(interaction_file, index=False)
                print(f"âœ… å·²æ›´æ–°ç”¨æˆ¶äº¤äº’æ–‡ä»¶: {interaction_file}")
            else:
                print(f"âš ï¸ é›»å½±å·²å­˜åœ¨æ–¼ç”¨æˆ¶äº¤äº’è¨˜éŒ„ä¸­")
        else:
            new_record.to_csv(interaction_file, index=False)
            print(f"âœ… å·²å‰µå»ºæ–°çš„ç”¨æˆ¶äº¤äº’æ–‡ä»¶: {interaction_file}")
        
        os.chdir(original_dir)
        print(f"ğŸ‰ è™•ç†å®Œæˆï¼Œè¿”å›æˆåŠŸ")
        return True
        
    except Exception as e:
        print(f"âŒ æ·»åŠ é›»å½±åˆ°äº¤äº’è¨˜éŒ„å¤±æ•—: {str(e)}")
        print(f"âŒ éŒ¯èª¤é¡å‹: {type(e).__name__}")
        import traceback
        print(f"âŒ è©³ç´°éŒ¯èª¤: {traceback.format_exc()}")
        os.chdir(original_dir)
        return False

def get_recommendations_data(target_user_id, num_recommendations=20):
    try:
        original_dir = os.getcwd()
        os.chdir(RL_RECOMMENDER_PATH)
        
        movies_info = load_movie_info()
        users_info = load_user_info()
        
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        user_embeddings = torch.load("model/RS/user_emb.pt", map_location=device, weights_only=True)
        item_embeddings = torch.load("model/RS/item_emb.pt", map_location=device, weights_only=True)
        
        uid_map, mid_map, reverse_uid_map, reverse_mid_map, mapping_success = load_mapping_files()
        
        if not mapping_success:
            os.chdir(original_dir)
            return None, "ç„¡æ³•è¼‰å…¥æ˜ å°„æ–‡ä»¶"
        
        # ğŸ¯ ç°¡åŒ–ç‰ˆï¼šåˆå§‹åŒ–æ¨¡å‹ï¼ˆéšŠå‹å»ºè­°çš„åŠŸèƒ½ï¼‰
        try:
            if initialize_model_for_dynamic_updates():
                print("ğŸ¯ æ¨¡å‹åˆå§‹åŒ–æˆåŠŸï¼Œæ”¯æ´å‹•æ…‹æ›´æ–°")
            else:
                print("âš ï¸ æ¨¡å‹åˆå§‹åŒ–å¤±æ•—ï¼Œä½¿ç”¨åŸå§‹æ–¹æ³•")
                
        except Exception as cache_error:
            print(f"âš ï¸ æ¨¡å‹åˆå§‹åŒ–å¤±æ•—: {str(cache_error)}")
        
        user_interactions_df, watched_movie_ids = get_user_interactions(target_user_id, reverse_uid_map, reverse_mid_map)
        
        if target_user_id >= user_embeddings.shape[0] or target_user_id < 0:
            error_msg = f"ç”¨æˆ¶ID {target_user_id} è¶…å‡ºç¯„åœ (0-{user_embeddings.shape[0]-1})"
            os.chdir(original_dir)
            return None, error_msg
        
        # ğŸ”„ å˜—è©¦ä½¿ç”¨å‹•æ…‹æ›´æ–°çš„ embeddings
        try:
            recommended_items, scores = get_dynamic_recommendations(
                target_user_id, num_recommendations, exclude_ids=watched_movie_ids
            )
            if recommended_items is not None:
                print("âœ… ä½¿ç”¨å‹•æ…‹æ›´æ–°çš„ embeddings ç”Ÿæˆæ¨è–¦")
            else:
                raise Exception("å‹•æ…‹æ¨è–¦å¤±æ•—")
        except:
            recommended_items, scores = get_user_recommendations(
                user_embeddings, item_embeddings, target_user_id, num_recommendations,
                exclude_ids=watched_movie_ids
            )
            print("âš ï¸ ä½¿ç”¨åŸå§‹ embeddings ç”Ÿæˆæ¨è–¦")
        
        recommendations_data = {
            'user_id': target_user_id,
            'recommended_items': recommended_items,
            'scores': scores,
            'movies_info': movies_info,
            'users_info': users_info,
            'user_interactions_df': user_interactions_df,
            'watched_movie_ids': watched_movie_ids,
            'reverse_uid_map': reverse_uid_map,
            'reverse_mid_map': reverse_mid_map,
            'user_embeddings': user_embeddings
        }
        
        os.chdir(original_dir)
        return recommendations_data, "æˆåŠŸç”Ÿæˆæ¨è–¦"
        
    except Exception as e:
        error_msg = f"æ¨è–¦ç”Ÿæˆå‡ºéŒ¯: {str(e)}"
        os.chdir(original_dir)
        return None, error_msg

def get_simulator_recommendations_data(target_user_id, num_recommendations=20):
    """
    ç²å– Simulator æ¨¡å‹çš„æ¨è–¦æ•¸æ“šï¼Œä½†ä¸é¡¯ç¤º
    """
    data, msg = run_simulator_exposure(
        target_user_id=target_user_id, 
        num_recommendations=num_recommendations
    )
    if data is None:
        return None, msg
    
    movies_info = load_movie_info()
    users_info = load_user_info()
    data['movies_info'] = movies_info
    data['users_info'] = users_info
    
    return data, msg

def display_recommendations(output_container, recommendations_data):
    """
    é¡¯ç¤ºæ¨è–¦çµæœ - å¾ä¿å­˜çš„æ•¸æ“šä¸­æ¸²æŸ“ç•Œé¢
    """
    if not recommendations_data:
        output_container.error("æ²’æœ‰æ¨è–¦æ•¸æ“šå¯é¡¯ç¤º")
        return
    
    target_user_id = recommendations_data['user_id']
    recommended_items = recommendations_data['recommended_items']
    scores = recommendations_data['scores']
    movies_info = recommendations_data['movies_info']
    users_info = recommendations_data['users_info']
    user_interactions_df = recommendations_data['user_interactions_df']
    watched_movie_ids = recommendations_data['watched_movie_ids']
    reverse_uid_map = recommendations_data['reverse_uid_map']
    reverse_mid_map = recommendations_data['reverse_mid_map']
    user_embeddings = recommendations_data['user_embeddings'] # ç²å–ç”¨æˆ¶åµŒå…¥
    
    output_container.success("Heuristic æ¨è–¦å®Œæˆï¼")
    
    # é¡¯ç¤ºç”¨æˆ¶ä¿¡æ¯
    user_info = users_info.get(target_user_id + 1, {})  # ç”¨æˆ¶IDå¾1é–‹å§‹
    if user_info:
        output_container.subheader(f"ğŸ‘¤ ç”¨æˆ¶ {target_user_id} çš„è©³ç´°ä¿¡æ¯")
        
        # è·æ¥­ä»£ç¢¼åˆ°åç¨±çš„æ˜ å°„
        occupation_map = {
            0: "å…¶ä»–", 1: "å­¸è¡“/æ•™è‚²", 2: "è—è¡“å®¶", 3: "è¡Œæ”¿", 4: "å¤§å­¸/ç ”ç©¶ç”Ÿ",
            5: "å®¢æˆ¶æœå‹™", 6: "é†«ç”Ÿ/é†«ç™‚ä¿å¥", 7: "é«˜éšä¸»ç®¡/ç®¡ç†", 8: "è¾²å¤«", 9: "å®¶åº­ä¸»å©¦",
            10: "K-12 å­¸ç”Ÿ", 11: "å¾‹å¸«", 12: "ç¨‹å¼è¨­è¨ˆå¸«", 13: "é€€ä¼‘", 14: "éŠ·å”®/å¸‚å ´è¡ŒéŠ·",
            15: "ç§‘å­¸å®¶", 16: "è‡ªåƒ±äººå£«", 17: "æŠ€è¡“å“¡/å·¥ç¨‹å¸«", 18: "æŠ€å·¥/å·¥åŒ ",
            19: "å¤±æ¥­", 20: "ä½œå®¶"
        }
        occupation_name = occupation_map.get(user_info['occupation'], "æœªçŸ¥")

        # ä½¿ç”¨è¡¨æ ¼å½¢å¼ç¢ºä¿å®Œæ•´é¡¯ç¤º
        import pandas as pd
        user_data = pd.DataFrame({
            'æ€§åˆ¥': [user_info['gender']],
            'å¹´é½¡': [user_info['age']],
            'è·æ¥­': [occupation_name],
            'æ­·å²äº¤äº’': [f"{len(watched_movie_ids)} éƒ¨é›»å½±"]
        })
        output_container.dataframe(user_data, use_container_width=True, hide_index=True)

    output_container.subheader(f"ğŸ¯ ç‚ºç”¨æˆ¶ {target_user_id} çš„ Heuristic æ¨è–¦çµæœ")
    
    # æ·»åŠ è¡¨æ ¼æ¨™é¡Œ
    col1, col2, col3, col4, col5, col6 = output_container.columns([1, 1, 4, 3, 2, 3])
    with col1:
        output_container.write("**æ’å**")
    with col2:
        output_container.write("**é›»å½±ID**")
    with col3:
        output_container.write("**é›»å½±åç¨±**")
    with col4:
        output_container.write("**é¡å‹**")
    with col5:
        output_container.write("**æ¨è–¦åˆ†æ•¸**")
    with col6:
        output_container.write("**å–œæ„›**")
    
    output_container.write("---")
    
    # é¡¯ç¤ºæ¨è–¦çµæœè¡¨æ ¼ï¼Œä¸¦ç‚ºæ¯è¡Œæ·»åŠ æ„›å¿ƒæŒ‰éˆ•
    for i, (item_id, score) in enumerate(zip(recommended_items, scores)):
        # æ­£ç¢ºçš„IDæ˜ å°„é‚è¼¯ï¼šå°‡æ˜ å°„å¾Œçš„item_idè½‰æ›ç‚ºåŸå§‹é›»å½±ID
        original_movie_id = reverse_mid_map.get(item_id)
        if original_movie_id is None:
            continue  # è·³éç„¡æ³•æ˜ å°„çš„é›»å½±
        
        movie_info = movies_info.get(original_movie_id, {})
        movie_title = movie_info.get('title', 'æœªçŸ¥é›»å½±')
        movie_genres = ' | '.join(movie_info.get('genres', ['æœªçŸ¥']))
        
        col1, col2, col3, col4, col5, col6 = output_container.columns([1, 1, 4, 3, 2, 3])
        
        with col1:
            output_container.write(f"**{i+1}**")
        with col2:
            output_container.write(f"{original_movie_id}")  # é¡¯ç¤ºåŸå§‹é›»å½±ID
        with col3:
            output_container.write(f"**{movie_title}**")
        with col4:
            output_container.write(f"{movie_genres}")
        with col5:
            output_container.write(f"{score:.4f}")
        with col6:
            if output_container.button("â¤ï¸", key=f"heart_{target_user_id}_{i}", help="åŠ å…¥æˆ‘çš„æœ€æ„›"):
                # æ·»åŠ åˆ°ç”¨æˆ¶äº¤äº’è¨˜éŒ„ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹é›»å½±ID
                success = add_movie_to_interactions(target_user_id, original_movie_id, movie_info, reverse_uid_map, reverse_mid_map)
                
                if success:
                    output_container.success(f"â¤ï¸ å·²å°‡ã€Š{movie_title}ã€‹æ·»åŠ åˆ°äº¤äº’è¨˜éŒ„ï¼")
                    # æ›´æ–° session_state ä¸­çš„äº¤äº’è¨˜éŒ„
                    import streamlit as st
                    if 'recommendations_data' in st.session_state:
                        # é‡æ–°ç²å–æ›´æ–°å¾Œçš„äº¤äº’è¨˜éŒ„
                        updated_interactions_df, updated_watched_ids = get_user_interactions(target_user_id, reverse_uid_map, reverse_mid_map)
                        st.session_state.recommendations_data['user_interactions_df'] = updated_interactions_df
                        st.session_state.recommendations_data['watched_movie_ids'] = updated_watched_ids
                else:
                    output_container.error("âŒ æ·»åŠ å¤±æ•—ï¼Œè«‹ç¨å¾Œå†è©¦")
    
    # é¡¯ç¤ºç”¨æˆ¶æ­·å²äº¤äº’è¨˜éŒ„
    if not user_interactions_df.empty:
        output_container.subheader(f"ğŸ“š ç”¨æˆ¶ {target_user_id} çš„æ­·å²äº¤äº’è¨˜éŒ„")
        output_container.info(f"æ•¸æ“šå·²ä¿å­˜è‡³: user_{target_user_id}_interactions.csv")
        
        # æŒ‰æ™‚é–“æˆ³é™åºæ’åˆ—
        sorted_interactions = user_interactions_df.sort_values('Timestamp', ascending=False)
        
        # é¡¯ç¤ºæ‰€æœ‰äº¤äº’è¨˜éŒ„
        output_container.dataframe(sorted_interactions, use_container_width=True)
        
        # é¡¯ç¤ºçµ±è¨ˆä¿¡æ¯
        output_container.info(f"ğŸ“Š å…± {len(sorted_interactions)} æ¢äº¤äº’è¨˜éŒ„")
    else:
        output_container.warning("è©²ç”¨æˆ¶æ²’æœ‰æ­·å²äº¤äº’è¨˜éŒ„")

    # æ·»åŠ ç¤¾ç¾¤æ¨è–¦åŠŸèƒ½
    output_container.markdown("---")
    output_container.subheader("ğŸ‘¥ ç¤¾ç¾¤æ¨è–¦ - çœ‹éé¡ä¼¼é›»å½±çš„ç”¨æˆ¶æ¨è–¦")
    
    try:
        # åˆ‡æ›åˆ° RL_recommender ç›®éŒ„
        original_dir = os.getcwd()
        os.chdir(RL_RECOMMENDER_PATH)
        
        # æ‰¾åˆ°æœ€ç›¸ä¼¼çš„å…©å€‹ç”¨æˆ¶ï¼ˆä½¿ç”¨å‚³å…¥çš„ç”¨æˆ¶åµŒå…¥ï¼‰
        similar_users, similarity_scores = find_similar_users(user_embeddings, target_user_id, num_similar_users=2)
        
        # ç‚ºæ¯å€‹ç›¸ä¼¼ç”¨æˆ¶é¡¯ç¤ºæ¨è–¦
        for i, (similar_user_id, similarity_score) in enumerate(zip(similar_users, similarity_scores)):
            # ç²å–è©²ç”¨æˆ¶çœ‹éçš„é«˜åˆ†é›»å½±
            watched_movies = get_user_watched_movies(similar_user_id, reverse_uid_map, reverse_mid_map, num_movies=5)
            
            if watched_movies:
                output_container.subheader(f"ğŸ¬ ç”¨æˆ¶ {similar_user_id} è·Ÿä½ çœ‹éé¡ä¼¼çš„é›»å½±ï¼Œæ‰€ä»¥ä½ ä¹Ÿå¯èƒ½å–œæ­¡çœ‹é€™äº›é›»å½±")
                output_container.info(f"ç›¸ä¼¼åº¦: {similarity_score:.4f}")
                
                # å‰µå»ºæ¨è–¦è¡¨æ ¼
                col1, col2, col3, col4, col5 = output_container.columns([1, 1, 4, 3, 2])
                with col1:
                    output_container.write("**æ’å**")
                with col2:
                    output_container.write("**é›»å½±ID**")
                with col3:
                    output_container.write("**é›»å½±åç¨±**")
                with col4:
                    output_container.write("**é¡å‹**")
                with col5:
                    output_container.write("**ç”¨æˆ¶è©•åˆ†**")
                
                output_container.write("---")
                
                # é¡¯ç¤ºæ¨è–¦é›»å½±
                for j, movie_data in enumerate(watched_movies):
                    movie_id = movie_data['movie_id']
                    rating = movie_data['rating']
                    
                    movie_info = movies_info.get(movie_id, {})
                    movie_title = movie_info.get('title', 'æœªçŸ¥é›»å½±')
                    movie_genres = ' | '.join(movie_info.get('genres', ['æœªçŸ¥']))
                    
                    col1, col2, col3, col4, col5 = output_container.columns([1, 1, 4, 3, 2])
                    
                    with col1:
                        output_container.write(f"**{j+1}**")
                    with col2:
                        output_container.write(f"{movie_id}")
                    with col3:
                        output_container.write(f"**{movie_title}**")
                    with col4:
                        output_container.write(f"{movie_genres}")
                    with col5:
                        output_container.write(f"â­ {rating}")
                
                if i < len(similar_users) - 1:  # å¦‚æœä¸æ˜¯æœ€å¾Œä¸€å€‹ç”¨æˆ¶ï¼Œæ·»åŠ åˆ†éš”ç·š
                    output_container.markdown("---")
            else:
                output_container.warning(f"ç”¨æˆ¶ {similar_user_id} æ²’æœ‰è¶³å¤ çš„è§€çœ‹è¨˜éŒ„")
        
        # åˆ‡æ›å›åŸç›®éŒ„
        os.chdir(original_dir)
        
    except Exception as e:
        output_container.error(f"ç¤¾ç¾¤æ¨è–¦åŠŸèƒ½å‡ºéŒ¯: {str(e)}")
        # ç¢ºä¿åˆ‡æ›å›åŸç›®éŒ„
        try:
            os.chdir(original_dir)
        except:
            pass

def run_simulator_exposure(target_user_id=None, num_recommendations=20):
    """
    é‹è¡Œ Simulator Exposure æ¨¡å‹ - ä½¿ç”¨ simulator ç›®éŒ„ä¸­çš„åŸå§‹ user embedding å’Œ item embedding
    """
    try:
        # åˆ‡æ›åˆ° RL_recommender ç›®éŒ„
        original_dir = os.getcwd()
        os.chdir(RL_RECOMMENDER_PATH)
        
        # è¼‰å…¥ç”¨æˆ¶å’Œé›»å½±ä¿¡æ¯
        movies_info = load_movie_info()
        users_info = load_user_info()
        
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        # ä½¿ç”¨ RS ç›®éŒ„ä¸­çš„åŸå§‹ embeddings
        user_embeddings = torch.load("model/RS/user_emb_raw.pt", map_location=device, weights_only=True)
        item_embeddings = torch.load("model/RS/item_emb_raw.pt", map_location=device, weights_only=True)
        
        # è½½å…¥æ˜ å°„æ–‡ä»¶
        uid_map, mid_map, reverse_uid_map, reverse_mid_map, mapping_success = load_mapping_files()
        
        if not mapping_success:
            error_msg = "ç„¡æ³•è¼‰å…¥æ˜ å°„æ–‡ä»¶"
            os.chdir(original_dir)
            return None, error_msg
        
        # ç²å–ç”¨æˆ¶æ­·å²äº¤äº’è¨˜éŒ„ï¼Œä»¥ä¾¿éæ¿¾æ¨è–¦
        user_interactions_df, watched_movie_ids = get_user_interactions(target_user_id, reverse_uid_map, reverse_mid_map)
        
        # æª¢æŸ¥ç”¨æˆ¶IDæ˜¯å¦æœ‰æ•ˆ
        if target_user_id >= user_embeddings.shape[0] or target_user_id < 0:
            error_msg = f"ç”¨æˆ¶ID {target_user_id} è¶…å‡ºç¯„åœ (0-{user_embeddings.shape[0]-1})"
            os.chdir(original_dir)
            return None, error_msg
        
        # ç‚ºç‰¹å®šç”¨æˆ¶ç”Ÿæˆæ¨è–¦ï¼Œä¸¦æ’é™¤å·²è§€çœ‹é›»å½±
        recommended_items, scores = get_user_recommendations(
            user_embeddings, item_embeddings, target_user_id, num_recommendations,
            exclude_ids=watched_movie_ids
        )
        
        # åˆ‡æ›å›åŸç›®éŒ„
        os.chdir(original_dir)
        
        return {
            'user_id': target_user_id,
            'recommended_items': recommended_items,
            'scores': scores,
            'user_interactions_df': user_interactions_df,
            'watched_movie_ids': watched_movie_ids,
            'reverse_uid_map': reverse_uid_map,
            'reverse_mid_map': reverse_mid_map,
            'user_embeddings': user_embeddings
        }, f"æˆåŠŸç‚ºç”¨æˆ¶ {target_user_id} ç”Ÿæˆäº† {len(recommended_items)} éƒ¨æ¨è–¦é›»å½±"
        
    except Exception as e:
        error_msg = f"Simulator æ¨è–¦åŸ·è¡Œå‡ºéŒ¯: {str(e)}"
        # ç¢ºä¿åˆ‡æ›å›åŸç›®éŒ„
        try:
            os.chdir(original_dir)
        except NameError: # original_dirå¯èƒ½å°šæœªå®šç¾©
            pass
        return None, error_msg

def display_simulator_recommendations(output_container, recommendations_data):
    """
    é¡¯ç¤º Simulator æ¨è–¦çµæœ - å¾ä¿å­˜çš„æ•¸æ“šä¸­æ¸²æŸ“ç•Œé¢
    """
    if not recommendations_data:
        output_container.error("æ²’æœ‰æ¨è–¦æ•¸æ“šå¯é¡¯ç¤º")
        return
    
    target_user_id = recommendations_data['user_id']
    recommended_items = recommendations_data['recommended_items']
    scores = recommendations_data['scores']
    movies_info = recommendations_data['movies_info']
    users_info = recommendations_data['users_info']
    user_interactions_df = recommendations_data['user_interactions_df']
    watched_movie_ids = recommendations_data['watched_movie_ids']
    reverse_uid_map = recommendations_data['reverse_uid_map']
    reverse_mid_map = recommendations_data['reverse_mid_map']
    user_embeddings = recommendations_data['user_embeddings'] # ç²å–ç”¨æˆ¶åµŒå…¥
    
    output_container.success("Simulator æ¨è–¦å®Œæˆï¼")
    
    # é¡¯ç¤ºç”¨æˆ¶ä¿¡æ¯
    user_info = users_info.get(target_user_id + 1, {})  # ç”¨æˆ¶IDå¾1é–‹å§‹
    if user_info:
        output_container.subheader(f"ğŸ‘¤ ç”¨æˆ¶ {target_user_id} çš„è©³ç´°ä¿¡æ¯")
        
        # è·æ¥­ä»£ç¢¼åˆ°åç¨±çš„æ˜ å°„
        occupation_map = {
            0: "å…¶ä»–", 1: "å­¸è¡“/æ•™è‚²", 2: "è—è¡“å®¶", 3: "è¡Œæ”¿", 4: "å¤§å­¸/ç ”ç©¶ç”Ÿ",
            5: "å®¢æˆ¶æœå‹™", 6: "é†«ç”Ÿ/é†«ç™‚ä¿å¥", 7: "é«˜éšä¸»ç®¡/ç®¡ç†", 8: "è¾²å¤«", 9: "å®¶åº­ä¸»å©¦",
            10: "K-12 å­¸ç”Ÿ", 11: "å¾‹å¸«", 12: "ç¨‹å¼è¨­è¨ˆå¸«", 13: "é€€ä¼‘", 14: "éŠ·å”®/å¸‚å ´è¡ŒéŠ·",
            15: "ç§‘å­¸å®¶", 16: "è‡ªåƒ±äººå£«", 17: "æŠ€è¡“å“¡/å·¥ç¨‹å¸«", 18: "æŠ€å·¥/å·¥åŒ ",
            19: "å¤±æ¥­", 20: "ä½œå®¶"
        }
        occupation_name = occupation_map.get(user_info['occupation'], "æœªçŸ¥")

        # ä½¿ç”¨è¡¨æ ¼å½¢å¼ç¢ºä¿å®Œæ•´é¡¯ç¤º
        import pandas as pd
        user_data = pd.DataFrame({
            'æ€§åˆ¥': [user_info['gender']],
            'å¹´é½¡': [user_info['age']],
            'è·æ¥­': [occupation_name],
            'æ­·å²äº¤äº’': [f"{len(watched_movie_ids)} éƒ¨é›»å½±"]
        })
        output_container.dataframe(user_data, use_container_width=True, hide_index=True)

    output_container.subheader(f"ğŸ¯ ç‚ºç”¨æˆ¶ {target_user_id} çš„ Simulator æ¨è–¦çµæœ")
    
    # æ·»åŠ è¡¨æ ¼æ¨™é¡Œ
    col1, col2, col3, col4, col5, col6 = output_container.columns([1, 1, 4, 3, 2, 3])
    with col1:
        output_container.write("**æ’å**")
    with col2:
        output_container.write("**é›»å½±ID**")
    with col3:
        output_container.write("**é›»å½±åç¨±**")
    with col4:
        output_container.write("**é¡å‹**")
    with col5:
        output_container.write("**æ¨è–¦åˆ†æ•¸**")
    with col6:
        output_container.write("**å–œæ„›**")
    
    output_container.write("---")
    
    # é¡¯ç¤ºæ¨è–¦çµæœè¡¨æ ¼ï¼Œä¸¦ç‚ºæ¯è¡Œæ·»åŠ æ„›å¿ƒæŒ‰éˆ•
    for i, (item_id, score) in enumerate(zip(recommended_items, scores)):
        # æ­£ç¢ºçš„IDæ˜ å°„é‚è¼¯ï¼šå°‡æ˜ å°„å¾Œçš„item_idè½‰æ›ç‚ºåŸå§‹é›»å½±ID
        original_movie_id = reverse_mid_map.get(item_id)
        if original_movie_id is None:
            continue  # è·³éç„¡æ³•æ˜ å°„çš„é›»å½±
        
        movie_info = movies_info.get(original_movie_id, {})
        movie_title = movie_info.get('title', 'æœªçŸ¥é›»å½±')
        movie_genres = ' | '.join(movie_info.get('genres', ['æœªçŸ¥']))
        
        col1, col2, col3, col4, col5, col6 = output_container.columns([1, 1, 4, 3, 2, 3])
        
        with col1:
            output_container.write(f"**{i+1}**")
        with col2:
            output_container.write(f"{original_movie_id}")  # é¡¯ç¤ºåŸå§‹é›»å½±ID
        with col3:
            output_container.write(f"**{movie_title}**")
        with col4:
            output_container.write(f"{movie_genres}")
        with col5:
            output_container.write(f"{score:.4f}")
        with col6:
            if output_container.button("â¤ï¸", key=f"sim_heart_{target_user_id}_{i}", help="åŠ å…¥æˆ‘çš„æœ€æ„›"):
                # æ·»åŠ åˆ°ç”¨æˆ¶äº¤äº’è¨˜éŒ„ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹é›»å½±ID
                success = add_movie_to_interactions(target_user_id, original_movie_id, movie_info, reverse_uid_map, reverse_mid_map)
                
                if success:
                    output_container.success(f"â¤ï¸ å·²å°‡ã€Š{movie_title}ã€‹æ·»åŠ åˆ°äº¤äº’è¨˜éŒ„ï¼")
                    # æ›´æ–° session_state ä¸­çš„äº¤äº’è¨˜éŒ„
                    import streamlit as st
                    if 'simulator_recommendations_data' in st.session_state:
                        # é‡æ–°ç²å–æ›´æ–°å¾Œçš„äº¤äº’è¨˜éŒ„
                        updated_interactions_df, updated_watched_ids = get_user_interactions(target_user_id, reverse_uid_map, reverse_mid_map)
                        st.session_state.simulator_recommendations_data['user_interactions_df'] = updated_interactions_df
                        st.session_state.simulator_recommendations_data['watched_movie_ids'] = updated_watched_ids
                else:
                    output_container.error("âŒ æ·»åŠ å¤±æ•—ï¼Œè«‹ç¨å¾Œå†è©¦")
    
    # é¡¯ç¤ºç”¨æˆ¶æ­·å²äº¤äº’è¨˜éŒ„
    if not user_interactions_df.empty:
        output_container.subheader(f"ğŸ“š ç”¨æˆ¶ {target_user_id} çš„æ­·å²äº¤äº’è¨˜éŒ„")
        output_container.info(f"æ•¸æ“šå·²ä¿å­˜è‡³: user_{target_user_id}_interactions.csv")
        
        # æŒ‰æ™‚é–“æˆ³é™åºæ’åˆ—
        sorted_interactions = user_interactions_df.sort_values('Timestamp', ascending=False)
        
        # é¡¯ç¤ºæ‰€æœ‰äº¤äº’è¨˜éŒ„
        output_container.dataframe(sorted_interactions, use_container_width=True)
        
        # é¡¯ç¤ºçµ±è¨ˆä¿¡æ¯
        output_container.info(f"ğŸ“Š å…± {len(sorted_interactions)} æ¢äº¤äº’è¨˜éŒ„")
    else:
        output_container.warning("è©²ç”¨æˆ¶æ²’æœ‰æ­·å²äº¤äº’è¨˜éŒ„")

    # æ·»åŠ ç¤¾ç¾¤æ¨è–¦åŠŸèƒ½
    output_container.markdown("---")
    output_container.subheader("ğŸ‘¥ ç¤¾ç¾¤æ¨è–¦ - çœ‹éé¡ä¼¼é›»å½±çš„ç”¨æˆ¶æ¨è–¦")
    
    try:
        # åˆ‡æ›åˆ° RL_recommender ç›®éŒ„
        original_dir = os.getcwd()
        os.chdir(RL_RECOMMENDER_PATH)
        
        # æ‰¾åˆ°æœ€ç›¸ä¼¼çš„å…©å€‹ç”¨æˆ¶ï¼ˆä½¿ç”¨å‚³å…¥çš„ç”¨æˆ¶åµŒå…¥ï¼‰
        similar_users, similarity_scores = find_similar_users(user_embeddings, target_user_id, num_similar_users=2)
        
        # ç‚ºæ¯å€‹ç›¸ä¼¼ç”¨æˆ¶é¡¯ç¤ºæ¨è–¦
        for i, (similar_user_id, similarity_score) in enumerate(zip(similar_users, similarity_scores)):
            # ç²å–è©²ç”¨æˆ¶çœ‹éçš„é«˜åˆ†é›»å½±
            watched_movies = get_user_watched_movies(similar_user_id, reverse_uid_map, reverse_mid_map, num_movies=5)
            
            if watched_movies:
                output_container.subheader(f"ğŸ¬ ç”¨æˆ¶ {similar_user_id} è·Ÿä½ çœ‹éé¡ä¼¼çš„é›»å½±ï¼Œæ‰€ä»¥ä½ ä¹Ÿå¯èƒ½å–œæ­¡çœ‹é€™äº›é›»å½±")
                output_container.info(f"ç›¸ä¼¼åº¦: {similarity_score:.4f}")
                
                # å‰µå»ºæ¨è–¦è¡¨æ ¼
                col1, col2, col3, col4, col5 = output_container.columns([1, 1, 4, 3, 2])
                with col1:
                    output_container.write("**æ’å**")
                with col2:
                    output_container.write("**é›»å½±ID**")
                with col3:
                    output_container.write("**é›»å½±åç¨±**")
                with col4:
                    output_container.write("**é¡å‹**")
                with col5:
                    output_container.write("**ç”¨æˆ¶è©•åˆ†**")
                
                output_container.write("---")
                
                # é¡¯ç¤ºæ¨è–¦é›»å½±
                for j, movie_data in enumerate(watched_movies):
                    movie_id = movie_data['movie_id']
                    rating = movie_data['rating']
                    
                    movie_info = movies_info.get(movie_id, {})
                    movie_title = movie_info.get('title', 'æœªçŸ¥é›»å½±')
                    movie_genres = ' | '.join(movie_info.get('genres', ['æœªçŸ¥']))
                    
                    col1, col2, col3, col4, col5 = output_container.columns([1, 1, 4, 3, 2])
                    
                    with col1:
                        output_container.write(f"**{j+1}**")
                    with col2:
                        output_container.write(f"{movie_id}")
                    with col3:
                        output_container.write(f"**{movie_title}**")
                    with col4:
                        output_container.write(f"{movie_genres}")
                    with col5:
                        output_container.write(f"â­ {rating}")
                
                if i < len(similar_users) - 1:  # å¦‚æœä¸æ˜¯æœ€å¾Œä¸€å€‹ç”¨æˆ¶ï¼Œæ·»åŠ åˆ†éš”ç·š
                    output_container.markdown("---")
            else:
                output_container.warning(f"ç”¨æˆ¶ {similar_user_id} æ²’æœ‰è¶³å¤ çš„è§€çœ‹è¨˜éŒ„")
        
        # åˆ‡æ›å›åŸç›®éŒ„
        os.chdir(original_dir)
        
    except Exception as e:
        output_container.error(f"ç¤¾ç¾¤æ¨è–¦åŠŸèƒ½å‡ºéŒ¯: {str(e)}")
        # ç¢ºä¿åˆ‡æ›å›åŸç›®éŒ„
        try:
            os.chdir(original_dir)
        except:
            pass

