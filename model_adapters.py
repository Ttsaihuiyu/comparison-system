import os
import sys
import torch
import numpy as np
import pandas as pd
from pathlib import Path
import pickle
from datetime import datetime

# Add RL_recommender to Python path
RL_RECOMMENDER_PATH = Path("../RL_recommender").resolve()
sys.path.append(str(RL_RECOMMENDER_PATH))

def load_movie_info():
    """
    è¼‰å…¥é›»å½±ä¿¡æ¯ï¼ˆIDã€æ¨™é¡Œã€é¡å‹ï¼‰
    """
    movies_file = RL_RECOMMENDER_PATH / "raw" / "ml-1m" / "movies.dat"
    movies_dict = {}
    
    with open(movies_file, 'r', encoding='latin-1') as f:
        for line in f:
            parts = line.strip().split("::")
            if len(parts) >= 3:
                movie_id = int(parts[0])
                title = parts[1]
                genres = parts[2].split("|")
                movies_dict[movie_id] = {
                    'title': title,
                    'genres': genres
                }
    return movies_dict

def load_user_info():
    """
    è¼‰å…¥ç”¨æˆ¶ä¿¡æ¯ï¼ˆIDã€æ€§åˆ¥ã€å¹´é½¡ã€è·æ¥­ï¼‰
    """
    users_file = RL_RECOMMENDER_PATH / "raw" / "ml-1m" / "users.dat"
    users_dict = {}
    
    # å¹´é½¡æ®µæ˜ å°„
    age_map = {
        1: "18æ­²ä»¥ä¸‹",
        18: "18-24æ­²",
        25: "25-34æ­²",
        35: "35-44æ­²",
        45: "45-49æ­²",
        50: "50-55æ­²",
        56: "56æ­²ä»¥ä¸Š"
    }
    
    # è·æ¥­æ˜ å°„
    occupation_map = {
        0: "å…¶ä»–/æœªæŒ‡å®š",
        1: "å­¸è¡“/æ•™è‚²å·¥ä½œè€…",
        2: "è—è¡“å®¶",
        3: "æ–‡è·/è¡Œæ”¿",
        4: "å¤§å­¸ç”Ÿ/ç ”ç©¶ç”Ÿ",
        5: "å®¢æˆ¶æœå‹™",
        6: "é†«ç”Ÿ/é†«ç™‚ä¿å¥",
        7: "é«˜ç´šç®¡ç†",
        8: "è¾²æ°‘",
        9: "å®¶åº­ä¸»å©¦",
        10: "ä¸­å°å­¸ç”Ÿ",
        11: "å¾‹å¸«",
        12: "ç¨‹åºå“¡",
        13: "é€€ä¼‘",
        14: "éŠ·å”®/å¸‚å ´",
        15: "ç§‘å­¸å®¶",
        16: "è‡ªç”±è·æ¥­",
        17: "æŠ€è¡“å“¡/å·¥ç¨‹å¸«",
        18: "å·¥åŒ ",
        19: "ç„¡æ¥­",
        20: "ä½œå®¶"
    }
    
    with open(users_file, 'r', encoding='latin-1') as f:
        for line in f:
            parts = line.strip().split("::")
            if len(parts) >= 5:
                user_id = int(parts[0])
                gender = "ç”·" if parts[1] == "M" else "å¥³"
                age = age_map.get(int(parts[2]), f"{parts[2]}æ­²")
                occupation = occupation_map.get(int(parts[3]), "æœªçŸ¥è·æ¥­")
                zip_code = parts[4]
                
                users_dict[user_id] = {
                    'gender': gender,
                    'age': age,
                    'occupation': occupation,
                    'zip_code': zip_code
                }
    return users_dict

def get_user_recommendations(user_embeddings, item_embeddings, user_id, num_recommendations=20):
    """
    ç‚ºç‰¹å®šç”¨æˆ¶ç”Ÿæˆé›»å½±æ¨è–¦
    """
    with torch.no_grad():
        # è¨ˆç®—ç”¨æˆ¶å’Œæ‰€æœ‰é›»å½±çš„ç›¸ä¼¼åº¦
        user_emb = user_embeddings[user_id].unsqueeze(0)  # shape: (1, emb_dim)
        scores = torch.mm(user_emb, item_embeddings.t()).squeeze()  # shape: (num_items,)
        
        # ç²å– top-k æ¨è–¦
        _, top_items = torch.topk(scores, num_recommendations)
        
        return top_items.cpu().numpy(), scores[top_items].cpu().numpy()

def run_heuristic_exposure(output_container=None, target_user_id=None, num_recommendations=20):
    """
    é‹è¡Œ Heuristic Exposure æ¨¡å‹ - ä½¿ç”¨ user embedding å’Œ item embedding
    """
    try:
        # åˆ‡æ›åˆ° RL_recommender ç›®éŒ„
        original_dir = os.getcwd()
        os.chdir(RL_RECOMMENDER_PATH)
        
        # è¼‰å…¥ç”¨æˆ¶å’Œé›»å½±ä¿¡æ¯
        movies_info = load_movie_info()
        users_info = load_user_info()
        
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        user_embeddings = torch.load("model/simulator/user_emb.pt", map_location=device, weights_only=True)
        item_embeddings = torch.load("model/simulator/item_emb.pt", map_location=device, weights_only=True)
        
        # è½½å…¥æ˜ å°„æ–‡ä»¶
        uid_map, mid_map, reverse_uid_map, reverse_mid_map, mapping_success = load_mapping_files()
        
        if not mapping_success:
            error_msg = "ç„¡æ³•è¼‰å…¥æ˜ å°„æ–‡ä»¶"
            if output_container:
                output_container.error(error_msg)
            os.chdir(original_dir)
            return error_msg
        
        # æª¢æŸ¥ç”¨æˆ¶IDæ˜¯å¦æœ‰æ•ˆ
        if target_user_id >= user_embeddings.shape[0] or target_user_id < 0:
            error_msg = f"ç”¨æˆ¶ID {target_user_id} è¶…å‡ºç¯„åœ (0-{user_embeddings.shape[0]-1})"
            if output_container:
                output_container.error(error_msg)
            os.chdir(original_dir)
            return error_msg
        
        # ç‚ºç‰¹å®šç”¨æˆ¶ç”Ÿæˆæ¨è–¦
        recommended_items, scores = get_user_recommendations(
            user_embeddings, item_embeddings, target_user_id, num_recommendations
        )
        
        # åˆ‡æ›å›åŸç›®éŒ„
        os.chdir(original_dir)
        
        if output_container:
            output_container.success("Heuristic æ¨è–¦å®Œæˆï¼")
            
            # ç²å–ç”¨æˆ¶æ­·å²äº¤äº’è¨˜éŒ„
            user_interactions_df, watched_movie_ids = get_user_interactions(target_user_id, reverse_uid_map, reverse_mid_map)
            
            # é¡¯ç¤ºç”¨æˆ¶ä¿¡æ¯
            user_info = users_info.get(target_user_id + 1, {})  # ç”¨æˆ¶IDå¾1é–‹å§‹
            if user_info:
                output_container.subheader(f"ğŸ‘¤ ç”¨æˆ¶ {target_user_id} çš„è©³ç´°ä¿¡æ¯")
                col1, col2, col3, col4 = output_container.columns(4)
                with col1:
                    output_container.metric("æ€§åˆ¥", user_info['gender'])
                with col2:
                    output_container.metric("å¹´é½¡", user_info['age'])
                with col3:
                    output_container.metric("è·æ¥­", user_info['occupation'])
                with col4:
                    output_container.metric("æ­·å²äº¤äº’", f"{len(watched_movie_ids)} éƒ¨é›»å½±")

            output_container.subheader(f"ğŸ¯ ç‚ºç”¨æˆ¶ {target_user_id} çš„ Heuristic æ¨è–¦çµæœ")
            
            # å‰µå»ºè©³ç´°çš„æ¨è–¦çµæœè¡¨æ ¼
            recommendations_data = []
            for i, (item_id, score) in enumerate(zip(recommended_items, scores)):
                movie_info = movies_info.get(item_id + 1, {})  # é›»å½±IDå¾1é–‹å§‹
                
                recommendations_data.append({
                    'æ’å': i + 1,
                    'é›»å½±ID': item_id,
                    'é›»å½±åç¨±': movie_info.get('title', 'æœªçŸ¥é›»å½±'),
                    'é¡å‹': ' | '.join(movie_info.get('genres', ['æœªçŸ¥'])),
                    'æ¨è–¦åˆ†æ•¸': f"{score:.4f}"
                })
            
            recommendations_df = pd.DataFrame(recommendations_data)
            
            # æ·»åŠ è¡¨æ ¼æ¨™é¡Œ
            col1, col2, col3, col4, col5, col6 = output_container.columns([1, 1, 4, 3, 2, 3])
            with col1:
                output_container.write("**æ’å**")
            with col2:
                output_container.write("**é›»å½±ID**")
            with col3:
                output_container.write("**é›»å½±åç¨±**")
            with col4:
                output_container.write("**é¡å‹**")
            with col5:
                output_container.write("**æ¨è–¦åˆ†æ•¸**")
            with col6:
                output_container.write("**å–œæ„›**")
            
            output_container.write("---")
            
            # é¡¯ç¤ºæ¨è–¦çµæœè¡¨æ ¼ï¼Œä¸¦ç‚ºæ¯è¡Œæ·»åŠ æ„›å¿ƒæŒ‰éˆ•
            for i, (item_id, score) in enumerate(zip(recommended_items, scores)):
                movie_info = movies_info.get(item_id + 1, {})
                movie_title = movie_info.get('title', 'æœªçŸ¥é›»å½±')
                movie_genres = ' | '.join(movie_info.get('genres', ['æœªçŸ¥']))
                
                col1, col2, col3, col4, col5, col6 = output_container.columns([1, 1, 4, 3, 2, 1])
                
                with col1:
                    output_container.write(f"**{i+1}**")
                with col2:
                    output_container.write(f"{item_id}")
                with col3:
                    output_container.write(f"**{movie_title}**")
                with col4:
                    output_container.write(f"{movie_genres}")
                with col5:
                    output_container.write(f"{score:.4f}")
                with col6:
                    if output_container.button("â¤ï¸", key=f"heart_{target_user_id}_{i}", help="åŠ å…¥æˆ‘çš„æœ€æ„›"):
                        # æ·»åŠ åˆ°ç”¨æˆ¶äº¤äº’è¨˜éŒ„
                        success = add_movie_to_interactions(target_user_id, item_id + 1, movie_info, reverse_uid_map, reverse_mid_map)
                        
                        if success:
                            output_container.success(f"â¤ï¸ å·²å°‡ã€Š{movie_title}ã€‹æ·»åŠ åˆ°äº¤äº’è¨˜éŒ„ï¼")
                            # æ›´æ–° session_state ä¸­çš„äº¤äº’è¨˜éŒ„
                            import streamlit as st
                            if 'recommendations_data' in st.session_state:
                                # é‡æ–°ç²å–æ›´æ–°å¾Œçš„äº¤äº’è¨˜éŒ„
                                updated_interactions_df, updated_watched_ids = get_user_interactions(target_user_id, reverse_uid_map, reverse_mid_map)
                                st.session_state.recommendations_data['user_interactions_df'] = updated_interactions_df
                                st.session_state.recommendations_data['watched_movie_ids'] = updated_watched_ids
                        else:
                            output_container.error("âŒ æ·»åŠ å¤±æ•—ï¼Œè«‹ç¨å¾Œå†è©¦")
            
            # é¡¯ç¤ºç”¨æˆ¶æ­·å²äº¤äº’è¨˜éŒ„
            if not user_interactions_df.empty:
                output_container.subheader(f"ğŸ“š ç”¨æˆ¶ {target_user_id} çš„æ­·å²äº¤äº’è¨˜éŒ„")
                output_container.info(f"æ•¸æ“šå·²ä¿å­˜è‡³: user_{target_user_id}_interactions.csv")
                
                # ç²å–æ¨è–¦é›»å½±çš„IDåˆ—è¡¨ï¼ˆéœ€è¦åŠ 1å› ç‚ºé›»å½±IDå¾1é–‹å§‹ï¼‰
                recommended_movie_ids = [item_id + 1 for item_id in recommended_items]
                
                # æ ¹æ“šæ˜¯å¦èˆ‡æ¨è–¦é‡è¤‡ä¾†é‡æ–°æ’åºäº¤äº’è¨˜éŒ„
                # å…ˆæ‰¾å‡ºèˆ‡æ¨è–¦é‡è¤‡çš„è¨˜éŒ„
                overlapping_records = user_interactions_df[user_interactions_df['Movie_ID'].isin(recommended_movie_ids)]
                non_overlapping_records = user_interactions_df[~user_interactions_df['Movie_ID'].isin(recommended_movie_ids)]
                
                # é‡æ–°çµ„åˆï¼šé‡è¤‡çš„è¨˜éŒ„æ’åœ¨å‰é¢ï¼ŒæŒ‰æ¨è–¦é †åºæ’åˆ—
                if not overlapping_records.empty:
                    # ç‚ºé‡è¤‡è¨˜éŒ„æ·»åŠ æ¨è–¦é †åºï¼Œä»¥ä¾¿æŒ‰æ¨è–¦é †åºæ’åˆ—
                    overlapping_records = overlapping_records.copy()
                    overlapping_records['recommendation_order'] = overlapping_records['Movie_ID'].map(
                        {movie_id: i for i, movie_id in enumerate(recommended_movie_ids)}
                    )
                    overlapping_records = overlapping_records.sort_values('recommendation_order').drop('recommendation_order', axis=1)
                    
                    # éé‡è¤‡è¨˜éŒ„æŒ‰æ™‚é–“æˆ³é™åºæ’åˆ—
                    non_overlapping_records = non_overlapping_records.sort_values('Timestamp', ascending=False)
                    
                    # çµ„åˆï¼šé‡è¤‡è¨˜éŒ„åœ¨å‰ï¼Œéé‡è¤‡è¨˜éŒ„åœ¨å¾Œ
                    sorted_interactions = pd.concat([overlapping_records, non_overlapping_records], ignore_index=True)
                else:
                    # å¦‚æœæ²’æœ‰é‡è¤‡ï¼ŒæŒ‰æ™‚é–“æˆ³é™åºæ’åˆ—
                    sorted_interactions = user_interactions_df.sort_values('Timestamp', ascending=False)
                
                # é¡¯ç¤ºæ‰€æœ‰äº¤äº’è¨˜éŒ„ï¼ˆä¸å†é™åˆ¶æ•¸é‡ï¼‰
                output_container.dataframe(sorted_interactions, use_container_width=True)
                
                # é¡¯ç¤ºçµ±è¨ˆä¿¡æ¯
                overlap_count = len(overlapping_records) if not overlapping_records.empty else 0
                if overlap_count > 0:
                    output_container.info(f"ğŸ¯ å…± {len(sorted_interactions)} æ¢äº¤äº’è¨˜éŒ„ï¼Œå…¶ä¸­ {overlap_count} æ¢èˆ‡æ¨è–¦é‡è¤‡ï¼ˆå·²ç½®é ‚é¡¯ç¤ºï¼‰")
                else:
                    output_container.info(f"ğŸ“Š å…± {len(sorted_interactions)} æ¢äº¤äº’è¨˜éŒ„")
            else:
                output_container.warning("è©²ç”¨æˆ¶æ²’æœ‰æ­·å²äº¤äº’è¨˜éŒ„")
        
        return f"æˆåŠŸç‚ºç”¨æˆ¶ {target_user_id} ç”Ÿæˆäº† {len(recommended_items)} éƒ¨æ¨è–¦é›»å½±"
        
    except Exception as e:
        error_msg = f"Heuristic æ¨è–¦åŸ·è¡Œå‡ºéŒ¯: {str(e)}"
        if output_container:
            output_container.error(error_msg)
        os.chdir(original_dir)
        return error_msg

def check_model_dependencies():
    """
    æª¢æŸ¥æ¨¡å‹ä¾è³´æ˜¯å¦æ»¿è¶³
    """
    try:
        # æª¢æŸ¥ RL_recommender ç›®éŒ„æ˜¯å¦å­˜åœ¨
        if not RL_RECOMMENDER_PATH.exists():
            return False, f"RL_recommender ç›®éŒ„ä¸å­˜åœ¨: {RL_RECOMMENDER_PATH}"
        
        # æª¢æŸ¥æ¨¡å‹æ–‡ä»¶
        user_emb_file = RL_RECOMMENDER_PATH / "model" / "simulator" / "user_emb.pt"
        item_emb_file = RL_RECOMMENDER_PATH / "model" / "simulator" / "item_emb.pt"
        
        if not user_emb_file.exists():
            return False, f"ç”¨æˆ¶åµŒå…¥æ–‡ä»¶ä¸å­˜åœ¨: {user_emb_file}"
            
        if not item_emb_file.exists():
            return False, f"é …ç›®åµŒå…¥æ–‡ä»¶ä¸å­˜åœ¨: {item_emb_file}"
        
        return True, "æ‰€æœ‰ä¾è³´æª¢æŸ¥é€šé"
        
    except Exception as e:
        return False, f"ä¾è³´æª¢æŸ¥å‡ºéŒ¯: {str(e)}"

def load_mapping_files():
    """
    è½½å…¥ç”¨æˆ·å’Œç”µå½±çš„æ˜ å°„æ–‡ä»¶
    """
    try:
        # è½½å…¥æ˜ å°„å…³ç³»
        uid_map_file = RL_RECOMMENDER_PATH / "mapping" / "uid_map.pkl"
        mid_map_file = RL_RECOMMENDER_PATH / "mapping" / "mid_map.pkl"
        
        with open(uid_map_file, 'rb') as f:
            uid_map = pickle.load(f)
        with open(mid_map_file, 'rb') as f:
            mid_map = pickle.load(f)
        
        # åˆ›å»ºåå‘æ˜ å°„ï¼ˆä»æ–°IDåˆ°æ—§IDï¼‰
        reverse_uid_map = {v: k for k, v in uid_map.items()}
        reverse_mid_map = {v: k for k, v in mid_map.items()}
        
        return uid_map, mid_map, reverse_uid_map, reverse_mid_map, True
    except Exception as e:
        print(f"è½½å…¥æ˜ å°„æ–‡ä»¶å¤±è´¥: {str(e)}")
        return {}, {}, {}, {}, False

def get_user_interactions(user_id, reverse_uid_map, reverse_mid_map):
    """
    è·å–ç”¨æˆ·çš„å†å²äº¤äº’è®°å½•
    """
    try:
        # è¯»å–æ•°æ®
        train_df = pd.read_csv(RL_RECOMMENDER_PATH / 'data/train.dat', sep=',', names=['user_id', 'movie_id', 'rating', 'timestamp'])
        val_df = pd.read_csv(RL_RECOMMENDER_PATH / 'data/val.dat', sep=',', names=['user_id', 'movie_id', 'rating', 'timestamp'])
        test_df = pd.read_csv(RL_RECOMMENDER_PATH / 'data/test.dat', sep=',', names=['user_id', 'movie_id', 'rating', 'timestamp'])
        
        movies = pd.read_csv(RL_RECOMMENDER_PATH / 'raw/ml-1m/movies.dat', sep='::', names=['movie_id', 'title', 'genres'], engine='python', encoding='latin-1')
        
        combined = pd.concat([train_df, val_df, test_df])
        
        # æ‰¾åˆ°è¯¥ç”¨æˆ·çš„æ‰€æœ‰äº¤äº’è®°å½•
        user_interactions = combined[combined['user_id'] == user_id].copy()
        
        if user_interactions.empty:
            return pd.DataFrame(), []
        
        # å°†movie_idè½¬æ¢å›åŸå§‹ID
        user_interactions['original_movie_id'] = user_interactions['movie_id'].map(reverse_mid_map)
        
        # ä¸moviesæ•°æ®åˆå¹¶
        result = pd.merge(
            user_interactions,
            movies,
            left_on='original_movie_id',
            right_on='movie_id',
            how='left'
        )
        
        # é€‰æ‹©è¦æ˜¾ç¤ºçš„æ ä½å¹¶é‡æ–°å‘½å
        result = result[['original_movie_id', 'title', 'genres', 'rating', 'timestamp']]
        result.columns = ['Movie_ID', 'Title', 'Genres', 'Rating', 'Timestamp']
        
        # æª¢æŸ¥é‡è¤‡é›»å½±ä¸¦å„ªå…ˆé¡¯ç¤ºé‡è¤‡çš„è¨˜éŒ„
        movie_counts = result['Movie_ID'].value_counts()
        duplicated_movies = movie_counts[movie_counts > 1].index.tolist()
        
        if duplicated_movies:
            # åˆ†é›¢é‡è¤‡å’Œéé‡è¤‡è¨˜éŒ„
            duplicated_records = result[result['Movie_ID'].isin(duplicated_movies)]
            non_duplicated_records = result[~result['Movie_ID'].isin(duplicated_movies)]
            
            # é‡è¤‡è¨˜éŒ„æŒ‰Movie_IDæ’åºï¼Œéé‡è¤‡è¨˜éŒ„æŒ‰æ™‚é–“æˆ³æ’åº
            duplicated_records = duplicated_records.sort_values(['Movie_ID', 'Timestamp'])
            non_duplicated_records = non_duplicated_records.sort_values('Timestamp', ascending=False)
            
            # é‡è¤‡è¨˜éŒ„å„ªå…ˆï¼Œç„¶å¾Œæ˜¯éé‡è¤‡è¨˜éŒ„
            result = pd.concat([duplicated_records, non_duplicated_records], ignore_index=True)
        else:
            # å¦‚æœæ²’æœ‰é‡è¤‡ï¼ŒæŒ‰æ™‚é–“æˆ³é™åºæ’åˆ—
            result = result.sort_values('Timestamp', ascending=False)
        
        # ä¿å­˜åˆ°CSVæ–‡ä»¶
        interaction_file = RL_RECOMMENDER_PATH / "interaction_collect" / f"user_{user_id}_interactions.csv"
        result.to_csv(interaction_file, index=False)
        
        # è¿”å›ç”¨æˆ·çœ‹è¿‡çš„ç”µå½±IDåˆ—è¡¨
        watched_movie_ids = user_interactions['movie_id'].tolist()
        
        return result, watched_movie_ids
        
    except Exception as e:
        print(f"è·å–ç”¨æˆ·äº¤äº’è®°å½•å¤±è´¥: {str(e)}")
        return pd.DataFrame(), []

def add_to_liked_movies(user_id, movie_info, liked_movies_file):
    """
    å°†ç”µå½±æ·»åŠ åˆ°ç”¨æˆ·å–œå¥½åå•
    """
    # åˆ›å»ºæ–°çš„å–œå¥½è®°å½•
    new_like = {
        'user_id': user_id,
        'movie_id': movie_info.get('movie_id'),
        'movie_title': movie_info.get('title'),
        'genres': movie_info.get('genres'),
        'liked_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    }
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    try:
        if os.path.exists(liked_movies_file):
            liked_df = pd.read_csv(liked_movies_file)
        else:
            liked_df = pd.DataFrame()
        
        # æ·»åŠ æ–°è®°å½•
        liked_df = pd.concat([liked_df, pd.DataFrame([new_like])], ignore_index=True)
        
        # ä¿å­˜æ–‡ä»¶
        liked_df.to_csv(liked_movies_file, index=False)
        return True
        
    except Exception as e:
        print(f"ä¿å­˜å–œå¥½è®°å½•å¤±è´¥: {str(e)}")
        return False

def get_user_liked_movies(user_id):
    """
    è·å–ç”¨æˆ·çš„å–œå¥½ç”µå½±åå•
    """
    liked_movies_file = f"user_{user_id}_liked_movies.csv"
    
    try:
        if os.path.exists(liked_movies_file):
            return pd.read_csv(liked_movies_file)
        else:
            return pd.DataFrame()
    except Exception as e:
        print(f"è¯»å–å–œå¥½è®°å½•å¤±è´¥: {str(e)}")
        return pd.DataFrame()

def add_movie_to_interactions(user_id, original_movie_id, movie_info, reverse_uid_map, reverse_mid_map):
    """
    å°‡é›»å½±æ·»åŠ åˆ°ç”¨æˆ¶çš„äº¤äº’è¨˜éŒ„ä¸­
    """
    try:
        print(f"ğŸ” é–‹å§‹è™•ç†: ç”¨æˆ¶{user_id}, é›»å½±ID{original_movie_id}")
        
        # åˆ‡æ›åˆ° RL_recommender ç›®éŒ„
        original_dir = os.getcwd()
        os.chdir(RL_RECOMMENDER_PATH)
        print(f"ğŸ“ åˆ‡æ›åˆ°ç›®éŒ„: {RL_RECOMMENDER_PATH}")
        
        # è®€å–ç¾æœ‰çš„äº¤äº’è¨˜éŒ„
        train_file = "data/train.dat"
        
        # æª¢æŸ¥é›»å½±IDæ˜ å°„
        mid_map_file = RL_RECOMMENDER_PATH / "mapping" / "mid_map.pkl"
        with open(mid_map_file, 'rb') as f:
            mid_map = pickle.load(f)
        
        # å°‡åŸå§‹é›»å½±IDè½‰æ›ç‚ºæ˜ å°„å¾Œçš„ID
        mapped_movie_id = mid_map.get(original_movie_id)
        if mapped_movie_id is None:
            print(f"âŒ é›»å½±ID {original_movie_id} ä¸åœ¨æ˜ å°„ä¸­")
            os.chdir(original_dir)
            return False
        
        print(f"âœ… é›»å½±IDæ˜ å°„æˆåŠŸ: {original_movie_id} -> {mapped_movie_id}")
        
        # ç”Ÿæˆæ–°çš„äº¤äº’è¨˜éŒ„
        current_timestamp = int(datetime.now().timestamp())
        new_interaction = f"{user_id},{mapped_movie_id},5,{current_timestamp}\n"  # çµ¦äºˆ5æ˜Ÿè©•åˆ†
        print(f"ğŸ“ æ–°äº¤äº’è¨˜éŒ„: {new_interaction.strip()}")
        
        # å°‡æ–°è¨˜éŒ„æ·»åŠ åˆ°è¨“ç·´æ•¸æ“šä¸­
        with open(train_file, 'a', encoding='utf-8') as f:
            f.write(new_interaction)
        print(f"âœ… å·²æ·»åŠ åˆ° {train_file}")
        
        # åŒæ™‚ä¿å­˜åˆ°å–®ç¨çš„ç”¨æˆ¶äº¤äº’æ–‡ä»¶
        interaction_file = f"interaction_collect/user_{user_id}_interactions.csv"
        
        # å‰µå»ºæ–°è¨˜éŒ„çš„æ•¸æ“šæ¡†
        new_record = pd.DataFrame({
            'Movie_ID': [original_movie_id],
            'Title': [movie_info.get('title', 'æœªçŸ¥é›»å½±')],
            'Genres': [' | '.join(movie_info.get('genres', ['æœªçŸ¥']))],
            'Rating': [5],
            'Timestamp': [current_timestamp]
        })
        
        # å¦‚æœæ–‡ä»¶å­˜åœ¨ï¼Œè®€å–ç¾æœ‰è¨˜éŒ„ä¸¦æ·»åŠ æ–°è¨˜éŒ„
        if os.path.exists(interaction_file):
            existing_df = pd.read_csv(interaction_file)
            # æª¢æŸ¥æ˜¯å¦å·²ç¶“å­˜åœ¨è©²é›»å½±è¨˜éŒ„
            if original_movie_id not in existing_df['Movie_ID'].values:
                updated_df = pd.concat([new_record, existing_df], ignore_index=True)
                updated_df.to_csv(interaction_file, index=False)
                print(f"âœ… å·²æ›´æ–°ç”¨æˆ¶äº¤äº’æ–‡ä»¶: {interaction_file}")
            else:
                print(f"âš ï¸ é›»å½±å·²å­˜åœ¨æ–¼ç”¨æˆ¶äº¤äº’è¨˜éŒ„ä¸­")
        else:
            new_record.to_csv(interaction_file, index=False)
            print(f"âœ… å·²å‰µå»ºæ–°çš„ç”¨æˆ¶äº¤äº’æ–‡ä»¶: {interaction_file}")
        
        os.chdir(original_dir)
        print(f"ğŸ‰ è™•ç†å®Œæˆï¼Œè¿”å›æˆåŠŸ")
        return True
        
    except Exception as e:
        print(f"âŒ æ·»åŠ é›»å½±åˆ°äº¤äº’è¨˜éŒ„å¤±æ•—: {str(e)}")
        print(f"âŒ éŒ¯èª¤é¡å‹: {type(e).__name__}")
        import traceback
        print(f"âŒ è©³ç´°éŒ¯èª¤: {traceback.format_exc()}")
        os.chdir(original_dir)
        return False

def get_recommendations_data(target_user_id, num_recommendations=20):
    """
    ç²å–æ¨è–¦æ•¸æ“šï¼Œä¸ç›´æ¥é¡¯ç¤ºç•Œé¢ - ç”¨æ–¼ç‹€æ…‹ç®¡ç†
    """
    try:
        # åˆ‡æ›åˆ° RL_recommender ç›®éŒ„
        original_dir = os.getcwd()
        os.chdir(RL_RECOMMENDER_PATH)
        
        # è¼‰å…¥ç”¨æˆ¶å’Œé›»å½±ä¿¡æ¯
        movies_info = load_movie_info()
        users_info = load_user_info()
        
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        user_embeddings = torch.load("model/simulator/user_emb.pt", map_location=device, weights_only=True)
        item_embeddings = torch.load("model/simulator/item_emb.pt", map_location=device, weights_only=True)
        
        # è¼‰å…¥æ˜ å°„æ–‡ä»¶
        uid_map, mid_map, reverse_uid_map, reverse_mid_map, mapping_success = load_mapping_files()
        
        if not mapping_success:
            os.chdir(original_dir)
            return None, "ç„¡æ³•è¼‰å…¥æ˜ å°„æ–‡ä»¶"
        
        # æª¢æŸ¥ç”¨æˆ¶IDæ˜¯å¦æœ‰æ•ˆ
        if target_user_id >= user_embeddings.shape[0] or target_user_id < 0:
            error_msg = f"ç”¨æˆ¶ID {target_user_id} è¶…å‡ºç¯„åœ (0-{user_embeddings.shape[0]-1})"
            os.chdir(original_dir)
            return None, error_msg
        
        # ç‚ºç‰¹å®šç”¨æˆ¶ç”Ÿæˆæ¨è–¦
        recommended_items, scores = get_user_recommendations(
            user_embeddings, item_embeddings, target_user_id, num_recommendations
        )
        
        # ç²å–ç”¨æˆ¶æ­·å²äº¤äº’è¨˜éŒ„
        user_interactions_df, watched_movie_ids = get_user_interactions(target_user_id, reverse_uid_map, reverse_mid_map)
        
        # æº–å‚™è¿”å›æ•¸æ“š
        recommendations_data = {
            'user_id': target_user_id,
            'recommended_items': recommended_items,
            'scores': scores,
            'movies_info': movies_info,
            'users_info': users_info,
            'user_interactions_df': user_interactions_df,
            'watched_movie_ids': watched_movie_ids,
            'reverse_uid_map': reverse_uid_map,
            'reverse_mid_map': reverse_mid_map
        }
        
        # åˆ‡æ›å›åŸç›®éŒ„
        os.chdir(original_dir)
        
        return recommendations_data, "æˆåŠŸç”Ÿæˆæ¨è–¦"
        
    except Exception as e:
        error_msg = f"æ¨è–¦ç”Ÿæˆå‡ºéŒ¯: {str(e)}"
        os.chdir(original_dir)
        return None, error_msg

def display_recommendations(output_container, recommendations_data):
    """
    é¡¯ç¤ºæ¨è–¦çµæœ - å¾ä¿å­˜çš„æ•¸æ“šä¸­æ¸²æŸ“ç•Œé¢
    """
    if not recommendations_data:
        output_container.error("æ²’æœ‰æ¨è–¦æ•¸æ“šå¯é¡¯ç¤º")
        return
    
    target_user_id = recommendations_data['user_id']
    recommended_items = recommendations_data['recommended_items']
    scores = recommendations_data['scores']
    movies_info = recommendations_data['movies_info']
    users_info = recommendations_data['users_info']
    user_interactions_df = recommendations_data['user_interactions_df']
    watched_movie_ids = recommendations_data['watched_movie_ids']
    reverse_uid_map = recommendations_data['reverse_uid_map']
    reverse_mid_map = recommendations_data['reverse_mid_map']
    
    output_container.success("Heuristic æ¨è–¦å®Œæˆï¼")
    
    # é¡¯ç¤ºç”¨æˆ¶ä¿¡æ¯
    user_info = users_info.get(target_user_id + 1, {})  # ç”¨æˆ¶IDå¾1é–‹å§‹
    if user_info:
        output_container.subheader(f"ğŸ‘¤ ç”¨æˆ¶ {target_user_id} çš„è©³ç´°ä¿¡æ¯")
        col1, col2, col3, col4 = output_container.columns(4)
        with col1:
            output_container.metric("æ€§åˆ¥", user_info['gender'])
        with col2:
            output_container.metric("å¹´é½¡", user_info['age'])
        with col3:
            output_container.metric("è·æ¥­", user_info['occupation'])
        with col4:
            output_container.metric("æ­·å²äº¤äº’", f"{len(watched_movie_ids)} éƒ¨é›»å½±")

    output_container.subheader(f"ğŸ¯ ç‚ºç”¨æˆ¶ {target_user_id} çš„ Heuristic æ¨è–¦çµæœ")
    
    # æ·»åŠ è¡¨æ ¼æ¨™é¡Œ
    col1, col2, col3, col4, col5, col6 = output_container.columns([1, 1, 4, 3, 2, 1])
    with col1:
        output_container.write("**æ’å**")
    with col2:
        output_container.write("**é›»å½±ID**")
    with col3:
        output_container.write("**é›»å½±åç¨±**")
    with col4:
        output_container.write("**é¡å‹**")
    with col5:
        output_container.write("**æ¨è–¦åˆ†æ•¸**")
    with col6:
        output_container.write("**å–œæ„›**")
    
    output_container.write("---")
    
    # é¡¯ç¤ºæ¨è–¦çµæœè¡¨æ ¼ï¼Œä¸¦ç‚ºæ¯è¡Œæ·»åŠ æ„›å¿ƒæŒ‰éˆ•
    for i, (item_id, score) in enumerate(zip(recommended_items, scores)):
        movie_info = movies_info.get(item_id + 1, {})
        movie_title = movie_info.get('title', 'æœªçŸ¥é›»å½±')
        movie_genres = ' | '.join(movie_info.get('genres', ['æœªçŸ¥']))
        
        col1, col2, col3, col4, col5, col6 = output_container.columns([1, 1, 4, 3, 2, 1])
        
        with col1:
            output_container.write(f"**{i+1}**")
        with col2:
            output_container.write(f"{item_id}")
        with col3:
            output_container.write(f"**{movie_title}**")
        with col4:
            output_container.write(f"{movie_genres}")
        with col5:
            output_container.write(f"{score:.4f}")
        with col6:
            if output_container.button("â¤ï¸", key=f"heart_{target_user_id}_{i}", help="åŠ å…¥æˆ‘çš„æœ€æ„›"):
                # æ·»åŠ åˆ°ç”¨æˆ¶äº¤äº’è¨˜éŒ„
                success = add_movie_to_interactions(target_user_id, item_id + 1, movie_info, reverse_uid_map, reverse_mid_map)
                
                if success:
                    output_container.success(f"â¤ï¸ å·²å°‡ã€Š{movie_title}ã€‹æ·»åŠ åˆ°äº¤äº’è¨˜éŒ„ï¼")
                    # æ›´æ–° session_state ä¸­çš„äº¤äº’è¨˜éŒ„
                    import streamlit as st
                    if 'recommendations_data' in st.session_state:
                        # é‡æ–°ç²å–æ›´æ–°å¾Œçš„äº¤äº’è¨˜éŒ„
                        updated_interactions_df, updated_watched_ids = get_user_interactions(target_user_id, reverse_uid_map, reverse_mid_map)
                        st.session_state.recommendations_data['user_interactions_df'] = updated_interactions_df
                        st.session_state.recommendations_data['watched_movie_ids'] = updated_watched_ids
                else:
                    output_container.error("âŒ æ·»åŠ å¤±æ•—ï¼Œè«‹ç¨å¾Œå†è©¦")
    
    # é¡¯ç¤ºç”¨æˆ¶æ­·å²äº¤äº’è¨˜éŒ„
    if not user_interactions_df.empty:
        output_container.subheader(f"ğŸ“š ç”¨æˆ¶ {target_user_id} çš„æ­·å²äº¤äº’è¨˜éŒ„")
        output_container.info(f"æ•¸æ“šå·²ä¿å­˜è‡³: user_{target_user_id}_interactions.csv")
        
        # ç²å–æ¨è–¦é›»å½±çš„IDåˆ—è¡¨ï¼ˆéœ€è¦åŠ 1å› ç‚ºé›»å½±IDå¾1é–‹å§‹ï¼‰
        recommended_movie_ids = [item_id + 1 for item_id in recommended_items]
        
        # æ ¹æ“šæ˜¯å¦èˆ‡æ¨è–¦é‡è¤‡ä¾†é‡æ–°æ’åºäº¤äº’è¨˜éŒ„
        # å…ˆæ‰¾å‡ºèˆ‡æ¨è–¦é‡è¤‡çš„è¨˜éŒ„
        overlapping_records = user_interactions_df[user_interactions_df['Movie_ID'].isin(recommended_movie_ids)]
        non_overlapping_records = user_interactions_df[~user_interactions_df['Movie_ID'].isin(recommended_movie_ids)]
        
        # é‡æ–°çµ„åˆï¼šé‡è¤‡çš„è¨˜éŒ„æ’åœ¨å‰é¢ï¼ŒæŒ‰æ¨è–¦é †åºæ’åˆ—
        if not overlapping_records.empty:
            # ç‚ºé‡è¤‡è¨˜éŒ„æ·»åŠ æ¨è–¦é †åºï¼Œä»¥ä¾¿æŒ‰æ¨è–¦é †åºæ’åˆ—
            overlapping_records = overlapping_records.copy()
            overlapping_records['recommendation_order'] = overlapping_records['Movie_ID'].map(
                {movie_id: i for i, movie_id in enumerate(recommended_movie_ids)}
            )
            overlapping_records = overlapping_records.sort_values('recommendation_order').drop('recommendation_order', axis=1)
            
            # éé‡è¤‡è¨˜éŒ„æŒ‰æ™‚é–“æˆ³é™åºæ’åˆ—
            non_overlapping_records = non_overlapping_records.sort_values('Timestamp', ascending=False)
            
            # çµ„åˆï¼šé‡è¤‡è¨˜éŒ„åœ¨å‰ï¼Œéé‡è¤‡è¨˜éŒ„åœ¨å¾Œ
            sorted_interactions = pd.concat([overlapping_records, non_overlapping_records], ignore_index=True)
        else:
            # å¦‚æœæ²’æœ‰é‡è¤‡ï¼ŒæŒ‰æ™‚é–“æˆ³é™åºæ’åˆ—
            sorted_interactions = user_interactions_df.sort_values('Timestamp', ascending=False)
        
        # é¡¯ç¤ºæ‰€æœ‰äº¤äº’è¨˜éŒ„ï¼ˆä¸å†é™åˆ¶æ•¸é‡ï¼‰
        output_container.dataframe(sorted_interactions, use_container_width=True)
        
        # é¡¯ç¤ºçµ±è¨ˆä¿¡æ¯
        overlap_count = len(overlapping_records) if not overlapping_records.empty else 0
        if overlap_count > 0:
            output_container.info(f"ğŸ“Š å…± {len(sorted_interactions)} æ¢äº¤äº’è¨˜éŒ„")
    else:
        output_container.warning("è©²ç”¨æˆ¶æ²’æœ‰æ­·å²äº¤äº’è¨˜éŒ„")

